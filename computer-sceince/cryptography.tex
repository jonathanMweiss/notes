
\begin{defn}[$\lambda$-bit strength]
  Defining the strength of security is complex. NIST decided that $\lambda$-bit security 
  means that for any kind of known attack, the attacker would need at least $2^{\lambda}$
  operations to break the scheme.

  Where each operation is defined as a single op over the specified field or ring.
  For instance, over an elliptic curve, either multiplication or additions are assumed to 
  take 1 single CPU cycle.
  
\end{defn}

\chapter{Basics}
\section{Diffie-Helman}
Diffie-Helman relies on the following assumption.

\begin{defn} [Decisional Diffie-Helman (DDH)]
  Consider a (multiplicative) cyclic group $\G$ of order $q$ and with generator $g$. 
  Given $g^a$ and $g^b$ for $a,b\in_R Z_q$ then $(g^a,g^b,g^{ab})$, $(g^a,g^b,g^{ab})$ are computationally indistinguishable:

  $$ \Pr[A((g^a,g^b,g^{ab}))=1] - \Pr[A(g^a,g^b,g^{c})=1]\le \delta(n)$$
  for $\delta(n)$ a negligable function in $n$.
\end{defn}

Given this assumption, which most of the world takes as FACT (until proven otherwise), then
we can define the key exchange protocol.
\paragraph{DH key exchange}
While not safe against man-in-the-middle attacks, DH is an excellent way to create a shared secret.
The protocol goes as follows.
Assume we have two players, Alice and Bob, both know the other's public key $g^a$ and $g^b$ respectfully,
each takes their secret key $a$ or $b$ and raises the other's public key to the power of $a$ (or $b$).
Both now hold $g^{ab}$, and no one else can compute it since they don't know the secret of either Bob or Alice.

Alice and Bob can use this new number/ or elliptic curve point $g^{ab}$ as a private key for
a symmetric encryption scheme like AES (e.g., $symKey=Hash(g^{ab})$).




\chapter{Elliptic curves}
Taken from \emph{A Graduate Course in Applied Cryptography, Dan Boneh and Victor Shoup}

The best-known discrete log algorithm in an elliptic curve group of size $q$ runs in time $O(\sqrt{q})$. 
This means that to provide security comparable to AES-128, it suffices to use a group of size $q \approx 2^{256}$ 
so that the time to compute discrete log is $\sqrt{q} \approx 2^{128}$.

\section{a bit of history on elliptic curves}
Elliptic curves come up naturally in several branches of mathematics.
Here we will follow their development as a branch of arithmetic (the study of rational numbers).
Diophantus, a greek mathematician who lived in Alexandria in the third century, was interested 
in the following problem: Given a bivariate polynomial equation, $f(x,y)=0$ find 
rational points satisfying the equation. That is, find $P=(x,y)$ such that $x,y\in\mathbb{Q}$.
Diophantus wrote a series of influential books on this subject, called the \emph{Arithmetica}, of which six survived.
Much of Arithmathica studies integer and rational solutions of quadratic equations.
For example, one of the first problems in the books regarding elliptic curves is to find $(x,y) \in \Q$
 that satisfy the equation $$ y^{2}=x^3 - x + 9$$
The method invented to answer this question secures most Internet traffic worldwide.
One can easily verify that the following points are on the curve $(0, \pm3), (1, \pm3), (-1, \pm 3)$.
Diophantus developed a method similar to \underline{chord method}:
Given two rational points $U$ and $V$ on the curve, where $U\neq -V$, we can pass a line through them,
 and this line must intersect the curve at a third rational point $W$. 
The chord method was rediscovered several times over the centuries, but it finally stuck with the work of Poincare.

Poincare defines the sum of $U, V$, denoted $U \boxplus V$ as $U \boxplus V := -W$
Diophantus' method, the \emph{tangent method} is another way to build a new rational point from a given rational point. 
We should later see that the method corresponds to adding the point $P$ to itself: $P\boxplus P$.
\section{elliptic curves over finite fields}
We are primarily interested in elliptic curves over finite fields for cryptographic applications.
\begin{defn}
  Let $p >3 $ be a prime. An \textbf{elliptic curve} $E$ defined over $\mathbb{F}_p$ is an 
  equation  
  $$ y^2 = x^3 +ax + b$$
  where $a,b \in \mathbb{F}_p$ satisfy $4a^3 +27b^2 \neq 0$. We write $E/\mathbb{F}_p$ to denote
  the fact that $E$ is defined over $\F_p$.
\end{defn}
The weird condition $4a^3 +27b^2 \neq 0 $ ensures that the equation 
$ x^3 + ax + b = 0$ does not have a double root (needed to avoid degeneracies).

\begin{defn}
  We say that point $P=(x,y)$, where $x,y \in \F_p$, is on curve $E$ if it satisfies the equation of $E$.
\end{defn}
\begin{defn}
  $E(\F)$ denotes the set of all points on the curve E and are defined over $\F$.
\end{defn}

The addition law, and adding to the set $E(F_p)$ the member $\mathcal{O}$,
 which servers as the identity member, turns it into a group. I'm not getting into the addition laws.

\section{Elliptic curve cryptography}
\red{TODO, put here an encryption scheme, and a signature scheme (can use schnorr here honestly)
The most important thing to remember is that elliptic curve cryptography 
assumes hard exponent, and everything is similar to those algorithms
}


Given two points $P$ and $\alpha \cdot P$, where $\alpha \in \Z_q$, it is hard to compute $\alpha$.
The best known algorithm to compute $\alpha$ is $\Omega(\sqrt{q})$.
There are a few exceptions to these rules, and thus one should be careful when defining a new curve.
So it's better to use some specific already implemented and used curve rather than 
generating a random prime $p$ and a random curve over $\F_p$.
\section{Pairing based cryptography}
We now show that certain elliptic curves have an additional structure,
called a pairing, which enables a world of new schemes that could not be built
 from discrete log groups without this other structure.

 \begin{defn}
  Let $\G_0, \G_1, \G_T$ be three cyclic groups of prime order $q$ where 
  $g_0\in\G_0$ and $g_1\in\G_1$ are generators. A \textbf{pairing} is an efficiently
  computable function $e: \G_0 \times \G_1 \to \G_T$ satisfying the 
  following properties:
  \begin{itemize}
    \item bilinear: $\forall u,u'\in\G_0, v,v'\in\G_1$  we have 
        $$ e(u\cdot u',v) = e(u,v) \cdot e(u',v) and  e(u,v\cdot v') = e(u,v)\cdot e(u,v')$$
    \item non-degenerate: $g_T := e(g_0,g_1)$  is a generator of $\G_T$.
  \end{itemize}
\end{defn}
We refer to $\G_0,\G_1$ as the pairing groups and $\G_T$ as the target group.

Bilinearity implies the following central property of pairing that will be used
in all our constructions: for all $a, b\in \Z_q$ we have
  $$ e(g_0^a,g_1^b)=e(g_0,g_1)^{a\cdot b}= e(g_0^b,g_1^a)$$
This equality follows from the equalities 
$e(g_0^a,g_1^b)=e(g_0,g_1^b)^a=e(g_0^a,g_1^b)=e(g_0^a,g_1)^b$
which are themselves a direct consequence of bilinearity (Note that in cyclic groups
 such as $\G_0 and \G_1$ this definition is equivalent to the definition of bilinearity above).
[if I understand correctly, due to $\G_0 and \G_1$ having generators, we can represent every number
as a power of the generators themselves, and using bilinearity we can reach the above equations]

In a symmetric pairing group, where $G_0 = G_1$ schemes like ElGamal aren't secure anymore,
that is, given two public keys, it is to break the DDH assumption: 
  $$ e(g^x,g^y) = e(g,g)^{x\cdot y}$$ 
Hence, it is possible to extract information. 

In asymmetric pairing, where $G_0 \neq G_1$, it may still be possible
that the DDH assumption holds in both $G_0$ and $G_1$. 

Furthermore, if the discrete log in $G_T$ is easy, it is easy in $G_0$ (and $G_1$).

\begin{rem}
  The pairing function $e$ on an elliptic curve comes from an algebraic pairing called the \textbf{Weil pairing}.
  Which can be efficiently evaluated. In practice, one uses variants of the weil 
  pairing, called the Tate and Ate pairings.
\end{rem}

We'll avoid $bn256$ curve as it isn't secure.


\subsection*{optimisations}
\begin{itemize}
  \item When the first value of the pairing is known, we can speed things up
  by calculating a table of the other possible values. (though it seems very inefficient, and memory intensive.)
\end{itemize}

\section{Advanced encryption schemes from pairings}

\subsection{The BLS signature scheme}
Let $e:F_0 \times G_1 \to G_T$ be a pairing where $G_0,G_1,G_T$ are
cyclic groups of prime order $q$, and where $g_0\in G_0, g_1\in G_1$ are
generators. 
We'll also require a hash function $H : \mathcal{M} \to G_0$.

The BLS signature scheme denoted $\mathcal{S}_BLS = (G,S,V)$, has message space
$\mathcal{M}$ and works as follows:
\begin{itemize}
  \item $G():$ The key generation algorithm runs as follows 
  $$  \alpha \from \Z_q,u\from g_1^\alpha \in G_1  $$
  The public key is $ pk := u$, and the secret key is $\alpha$.

  \item $S(sk,m):$ To sign a message $m\in \mathcal{M}$ using a secret key
  $sk=\alpha\in\Z_q$ do:
  $$ \sigma\from H(m)^{\alpha} \text{ output } \sigma$$

  \item $V(pk,m,\sigma):$ To verify a signature 
  $$ e(H(m), u) = e(\sigma,g_1) $$
  that is, the signature is accepted due to the following calculations
  $$e(H(m), g_1^\alpha) = e(H(m),g_1)^\alpha = e(H(m)^\alpha,g_1)= 
  e(\sigma, g_1)
  $$
\end{itemize}

\subsection{Identity based encryption}
Using Identity-Based Encryption (IBE from now), Alice can send an encrypted message to Bob
without asking for bobs key beforehand. Beyond key exchange, IBE can also 
be used to construct CPA-secure public key encryption and even search encrypted data.
In an IBE scheme, a trusted entity, Trudy, generates a master key pair $(mpk, msk)$.
The key $mpk$ is the \emph{master public key} and is known to everyone. Trudy keeps the \emph{master 
secret key} $msk$ to herself. When Bob wants to use his email address as his public key, he must
somehow obtain the private key derived from $msk$ and Bob's public key.
We denote Bob's email address as his (public) identity $id$ and denote the corresponding private key 
by $sk_{id}$. He receives $sk_{id}$ by contacting Trudy, she'll use $msk$ and $id$ to generate $sk_{id}$,
and send it back to Bob.
Now anyone, including Alice, can send bob messages without looking up his public key. 
Assuming, of course, that Alice knows $mpk$.

\begin{defn}
  An \textbf{Identiy based encryption scheme $ \mathcal{E}_id =(S,G,E,D)$}
  is a tuple of four efficient algorithms: a \textbf{setup algorithm $S$}, a 
  \textbf{Key generation algorithm $G$}, an \textbf{encryption algorithm $E$}
  and a \textbf{decryption algorithm $D$}.

  \begin{itemize}
    \item $S$ is a probabilistic algorithm which outputs $(mpk, msk) \overset{_R}{\leftarrow} S()$.
    \item $G$ is a probabilistic algorithm invoked as $sk_{id} \getrandom G(msk, id)$.
    \item $E$ is a \emph{probabilistic} algorithm invoked as $c \getrandom E(mpk, id, m)$.
    \item $D$ is a deterministic algorithm invoked as $m\getrandom D(sk_{id},c)$. Where $m$ is
      either a message or a \textbf{reject} value.
    \item We require that decryption undoes encryption: 
    $$ \Pr[D(G(msk,id), E(mpk,id,m))=m]=1$$
    \item identities, messages, and ciphertexts are in their respective finite spaces,
    and $\mathcal{E}_id$ is defined over $(\mathcal{ID},\mathcal{M},\mathcal{C})$.
  \end{itemize}
\end{defn}

We can view IBE as a particular public key encryption scheme where the messages
to be encrypted pairs $(id, m)\in\mathcal{ID\times M}$. The master secret key can
decrypt any well-formed ciphertext. However, there are weaker secret keys, 
such as $sk_{id}$ that can decrypt a ciphertext $c\getrandom E(mpk, id', m)$ only if $id'=id$.


Bob won't use his email address as a public key if a company uses IBE. Otherwise, if Bob's secret key 
is compromised, bob would need to change his email. Instead, Bob's public key
should bob could use the identity string $(id, date)$.
Bob will need to request a new secret key from Trudy every day.
Now Alice can even encrypt emails for specific dates, and bob cannot access it before that, 
unless Trudy gives bob any key he requests.

I will not go into detail about the formal definition of security, but the idea is that
the attacker has access to any $sk_{id'}$ it want but should not be able to break semantic
security for some other identity with secret key $sk_{id}$ that the adversary does not have.


\subsection*{IBE from pairings}
We'll need a few components before being able to construct an IBE: 
\begin{itemize}
  \item a pairing. as defined above, over cyclic groups of prime order $q$, 
  with generators $ g_0, g_1 $.
  \item a symmetric cipher $\mathcal{E}=(E_s,D_s)$.
  \item hash functions $H_0:\mathcal{ID}\to \G_0$ and $H_1:\G_1\times\G_T\to \mathcal{k}$,
  where k is the key space.
\end{itemize}
\subsubsection*{Construction 1}

\begin{itemize}
  \item $S():$ runs as follows:
  $$ \alpha\getrandom \Z_q, u_1\from g^\alpha, mpk \from u_1, msk \from \alpha 
  \text{ output }(mpk,msk) $$
  \item $G(msk,id):$ key generation using $msk = \alpha$:
  $$ sk_id \from H_0(id)^\alpha \in \G_0 \text{ output } sk_id$$
  \item $E(mpk, id, m ):$ encryption using the public parameters $mpk=u_1$:
  \begin{align*}\label{lamlam} 
    \beta \getrandom \Z_q,\  z\from e(H_0(id),mpk^\beta) 
    \\ \ 
    k\from H_1(g^\beta,z), c\getrandom E_s(k,m), \text{ output } (g^\beta,c)
  \end{align*}
  The encryption generates a new secret key $k$ at random. This private key relies on the pairing with
  the hashed public id. Once we've generated the ephemeral secret key $k$, we encrypt the message $m$.

  \item $D(sk_id,(w_1,c)):$ decryption using secret key $sk_id$ of ciphertext $(w_1,c)$:
  \begin{align*}
    z \from  e(sk_{id},w_1), k\from H_1(w_1, z), m\from D_s(k,c),
  \text{ output } m
  \end{align*}
  The decryption relies on $w_1=g^\beta$ to figure out the symmetric encryption key $k$.
  With $k$, the message can be decrypted.
  \newline
  To generate $k$ correctly, we first remind the reader that $$sk=H(id)^\alpha, mpk^\beta=g^{\alpha\beta}, k=H(g^\beta,z)$$
  now, let's compute $z$, our missing component:
  $$
  z=\underbrace{e(sk_{id},g^\beta)}_{\text{z in decryption}}=e(H(id)^\alpha,g^\beta)=e(H(id),g^{\alpha\beta})=\underbrace{e(H(id),mpk^\beta)}_{\text{z in encryption}}
  $$
\end{itemize}


\chapter{Fully Homomorphic Encryption}
\red{
  TODO; add homomorphic encryption definition. NOTE: they can support
multiple operations.
}

We can have both a symmetric key HE, or an asymmetric key HE. 

\section{Hardness}

Most HE schemes use different Hardness assumptions than DDH.

\subsection*{Learning with errors (LWE)}
In plain language, the basic hardness is called Learning with Errors,
and it assumes that no adversary can infer whether $Ax+e=c$ or $Ax=c$
just from seeing $A,c$. the formal definition:
\begin{defn}
Learning With Errors (LWE) Problem. The LWE problem is parametrized
by four parameters: $\left(n,m,q,\text{\ensuremath{\mx}}\right)$
where $n$ is a positive integer referred to as the \textquotedblleft dimension
parameter\textquotedblright , $m$ is \textquotedblleft the number
of samples\textquotedblright , $q$ is a positive integer referred
to as the \textquotedblleft modulus parameter\textquotedblright{}
and $\mx$ is a probability distribution over rational integers referred
to as the \textquotedblleft error distribution\textquotedblright .
The LWE assumption requires that the following two probability distributions
are computationally indistinguishable: 
\begin{description}
\item [{Distribution~1.}] Choose a uniformly random matrix $m\times n$
matrix $A$, a uniformly random vector $s$ from the vector space
$\Z_{q}^{n}$, and a vector $e$ from $\Z^{m}$ where each coordinate
is chosen from the error distribution $\mx$. Compute $c:=As+e$,
where all computations are carried out modulo $q$. Output $\left(A,c\right)$. 
\item [{Distribution~2.}] Choose a uniformly random $m\times n$ matrix
$A$, and a uniformly random vector $c$ from $\Z_{q}^{m}$ . Output
$\left(A,c\right)$. 
\end{description}

\paragraph{The error distribution $\protect\mx$ can be either a discrete Gaussian
distribution over the integers, a continuous Gaussian distribution
rounded to the nearest integer, or other distributions supported on
small integers.}
\end{defn}

\subsection*{Ring-LWE (RLWE)} Although different definition, it is quite similar.
This is the main definition I've worked with, used by BGV.

\begin{defn}
  For security parameter $\lambda$, let $f(x)=x^d+1$ where $d=d(\lambda)$ is a powerof 2.
  Let $q=q(\lambda)\geq 2$ be an integer. 
  Let $R = \Z[x]/(f(x))$ and let $R_q = R/qR$. 
  Let $\mx = \mx(\lambda)$ be a distribution over $R$.
  The RLWE $d,q,\mx$ problem is to distinguish the following two distributions:
  In the first distribution, one samples $(a_i,b_i)$ uniformly from $R_q^2$.
  In the second distribution,
  one first draws $s\leftarrow R_q$ uniformly and then samples $(a_i,b_i)\in R_q^2$
  By sampling $a_i\leftarrow R_q$ uniformly, $e_i \leftarrow \mx$,
  and then compute $b_i=a_i\cdot s +e_i$.
  The RLWE $d,q,\mx$ assumption is that the RLWE $d,q,\mx$ problem is infeasible.
\end{defn}


\section{The BGV and BFV Encryption schemes}
BFV is instantiated over two rings:
\begin{enumerate}
\item The plaintext ring which includes encodings of unencrypted or intelligible
messages;
\item The ciphertext ring which includes encrypted messages.
\end{enumerate}
Similar to any other FHE scheme, BFV allows an untrusted party to
induce meaningful computation over en- crypted data without access
to the decryption key.

\subsection{BFV Primitives}

The scheme consists of numerous algorithms:
\begin{itemize}
\item $ParamGen(\lambda)\to Params$ : Parameter generator (ParamGen) takes
as input the security parameter $\lambda$, which is a number used
to define the security level of BFV, and returns a set of encryption
parameters used in BFV. One can view $\lambda$ as the computational
cost of successful attacks on the scheme. In order for these attacks
to succeed with probability 1, they would require $2^{\lambda}$ basic
computational operations.
\item $KeyGen\left(Params\right)\to\left(sk,pk,ek\right)$: Key generation
(KeyGen) takes as input the encryption parameters and a secret key,
a public key and evaluation key. 

\paragraph{The secret key $sk$ is mainly used for decryption, the public key
$pk$ is used for encryption, and the evaluation key $ek$which is
used to evaluate homomorphic operations on ciphertexts as we shall
see later. Both the $pk$ and the $ek$ can be public.}
\item $Encrypt\left(pk,m\right)\to c$: Encrypt takes as input $pk$ and
a plaintext message $m$ in the plaintext space $P$, and returns
a valid ciphertext $c$ from the ciphertext space $\mathcal{C}$.
\item $Decrypt\left(sk,c\right)\to m$: Decrypt takes as input $sk$ and
a valid ciphertext $c$ in $\mathcal{C}$, which encrypts message
$m$ in $P$, and returns $m$.
\item $EvalAdd\left(params,ek,c_{1},c_{2}\right)\to c$: takes two ciphertexts
and adds their underlying value $m_{1,}m_{2}$ respectively. outputs
the encryption of $m_{1}+m_{2}$

\paragraph{we can even switch $c_{1}$ or $c_{2}$ with a plaintext $m$. the
result would be the encryption of the addition between the plain text
and the underlying encrypted value.}
\item $evalMult$ same thing...
\item more ops$\dots$
\end{itemize}

\section{Plaintext and Ciphertext Spaces}
\begin{defn}
The notation $\Z_{a}\left[x\right]/\left(x^{n}+1\right)$ can be viewed
as the set of polynomials with integer coefficients modulo both a
and $\left(x^{n}+1\right)$, i.e., with coefficients in $\left\{ \lceil-\frac{a}{2}\rceil,\dots\lfloor\frac{a-1}{2}\rfloor\right\} $
(from $-a/2$ to $a/2$ ) and of degree less than $n$. (i've read
another definition, where we can just have coefficients modulo $a$.
\begin{itemize}
\item K{[}x{]} will meanthat $k$ is the field we choose our coefficients
from. and $x$ is the number of variables. 
\end{itemize}
\end{defn}

\begin{example}
The following examples are of valid plaintext messages for the parameters
$n=4$ (degree must be less than that) and $t=5$ (to choose coefficients):
\begin{enumerate}
\item $m_{0}=1+2x+1\cdot x^{2}-1\cdot x^{3}$
\item $m_{2}=-1-2x-1x^{2}+2x^{3}$ 
\end{enumerate}
\end{example}

The plaintext and ciphertext spaces in BFV are defined over two distinct
polynomial rings. the plaintext space is denoted by the polynomial
ring $\mathcal{P}=R_{t}=\Z_{t}\left[x\right]/\left(x^{n}+1\right)$,
that is, polynomials of degree less than $n$ with coefficients modulo
$t$. \\
the ciphertext space is denoted by $\mathcal{C}=\left(\Z_{q}\left[x\right]/\left(x^{n}+1\right)\right)\times\left(\Z_{q}\left[x\right]/\left(x^{n}+1\right)\right)$. 

\section{BFV params}

basically, some random distributions. 
\begin{itemize}
\item $R_{2}$ used to sample polynomials with coefficients in $\left\{ -1,0,1\right\} $.
\item $\mx$ is the error distribution, which is discrete Gaussian distribution.
\item $R_{q}$ is a uniform random distribution over $R_{q}$.
\end{itemize}

\section{Plaintext Encoding and Decoding}

Recall that the plaintext space is the polynomial ring $R_{t}$. This
means that messages need to be converted to polynomials in $R_{t}$.
Let $m$ denote an integer message we would like to encrypt in FHE.
The first encoding scheme (let\textquoteright s call it the naive
encoding scheme) composes the plaintext element (polynomial) as $M=m+0\cdot x+0\cdot x^{2}+\cdot\cdot\cdot+0\cdot x^{n-1}$,
the constant polynomial. this scheme is extremely naive and inefficient.
Let's do better.

\paragraph{another simple solution, but effective, would be to take the message
$m$'s binary representation $a_{0}a_{1}a_{2}\dots$ and convert them
to the coefficients of the polynomial. If we have less bits than coefficients,
set all coefficients with matching bits as $0$. Probably can take
the bytes instead of simple bits too. }

\paragraph{To ensure that the results of homomorphic evaluation matches the
expected results of the computation of interest, we need to ensure
that the degree of the plaintext coefficient does not wrap around
$n$ and the coefficients do not wrap around $t$.}

\section{Key generation}

The secret key $sk$ is generated as a random ternary polynomial from
$R_{2}$, a polynomial of degree $n$ with coefficients in $\left\{ -1,0,1\right\} $.

\paragraph{The public key $pk$ is a pair of polynomials $\left(pk_{1},pk_{2}\right)$
calculated as follows: }

\begin{align*}
pk_{1} & =\left[-1\cdot\left(a\cdot sk+e\right)\right]_{q}\\
pk_{2} & =a
\end{align*}
 Where $a$ is a random ploynomial in $R_{q}$ ($R_{q}=\Z_{q}\left[x\right]/\left(x^{n}+1\right)$).
$e$ is a random error polynomial sampled from $\mx$. the notation
$\left[\cdot\right]_{q}$ means that the polynomial arithemtic should
be done modulo $q$. Note that as $ok_{2}$ is in $R_{q}$, polynomial
arithmetic should also be performed modulo the ring polynomial modulus
$\left(x^{n}+1\right)$.

\section{Encryption and Decryption }

encrypting an encoded message $m$ requires $3$ small random polynomials\"{ }$u\in R_{2}$
and $e_{1},e_{2}\in\mx$. the ciphertext $c=\left(c_{1},c_{2}\right)$
is generated as follows:
\begin{align*}
c_{1} & =\left[pk_{1}\cdot u+e_{1}+\lfloor\frac{q}{t}\rfloor\cdot m\right]q\\
c_{2} & =\left[pk_{2}\cdot u+e_{2}\right]
\end{align*}

Decryption is performed by evaluating the ciphertext on the secret
key as follows and inverting the scaling factor $\left(\lfloor\frac{q}{t}\rfloor\right)$
applied in the encryption:
\[
m=\left[\lceil\frac{t\cdot\left[c_{1}+c_{2}\cdot sk\right]q}{q}\rceil\right]t
\]
 let us expand this to gain better understanding.
\begin{align*}
c_{1}+c_{2}\cdot sk & =pk_{1}\cdot u+e_{1}+\lfloor\frac{q}{t}\rfloor\cdot m+\left(pk_{2}\cdot u+e_{2}\right)\cdot sk=\\
 & =\underbrace{-\left(a\cdot sk+e\right)}_{pk_{1}}\cdot u+e_{1}+\lfloor\frac{q}{t}\rfloor\cdot m+a\cdot u\cdot sk+e_{2}\cdot sk=\\
 & =\cancel{-a\cdot u\cdot sk}-e\cdot u+e_{q}+\lfloor\frac{q}{t}\rfloor\cdot m+\cancel{a\cdot u\cdot sk}+e_{2}\cdot sk=\\
 & =\lfloor\frac{q}{t}\rfloor\cdot m-e\cdot u+e_{1}+e_{2}\cdot sk\\
 & =\lfloor\frac{q}{t}\rfloor\cdot m+\underbrace{e_{1}+e_{2}\cdot sk-e\cdot u}=\lfloor\frac{q}{t}\rfloor\cdot m+v
\end{align*}
 the infinity norm of $v$ (largest abs value from the coefficients)
is pretty small: all of these: $sk,e,e_{1},e_{2}$ are all \textbf{\uline{small}}
polynomials. \.{I}f these polynomials are bounded by some $\beta$
then $\left|\left|v\right|\right|\le2n\cdot\beta^{2}+\beta$. (I'm
skipping the proof of that). \\
They ensure that the noise is small, and thus they can recovering
it.

\section{Doing ops:}

addition is very simple, and the additional error is not high. (can
just add the cipher-texts together). Multiplication adds a lot of
noise, in addition to that, from $2$ cipher-text\.{s} we get $3$
output cipher-texts (polynomials) which means a different encryption
procedure (can be done by using exponents of the secret key). To overcome
this one should do relinearization. 

\section{Maintenance Operations}

The BFV scheme include operations that do not effect the underlying
plaintext, but are needed for implementation reasons:

\paragraph{According to the ``Protecting Privacy through Homomorphic Encryption''
ciphertext-ciphertext multiplication have a side effect of requiring
a different secret--key to decrypt the result than what was needed
before the operation. thus, multiplication is followed by a key switching
opeation to restore the secret key back to the original one. (relinearization).
Avoiding relianirization is possible, but will reduce noise budget
quicker. In addition to that, ops on non-relinearized ciphertexts
are much slower.}

\paragraph{Another such operation is \textbf{bootstrapping}, which ``refreshes''
a ciphertext and reduces the level of noit in it, to support more
computations. It is a very expensive operation, and hence it isn't
often used/ implemented}

\section{security of the scheme}

Choosing optimal BFV parameters that maximize performance and respect
security and functionality constraints is an art that is practiced
by expert cryptographers. but there is a standard one can follow.

But mainly, we first start by choosing the max size of integers $\left(q\right)$
for the coefficients, and the max polynomial degree $\left(n\right)$.
but generally, larger $n$ gives more security (but slower ops), larger
$q$ means we can do more complex computations. 

\paragraph{Ciphertexts in these encryption schemes contain a noise component
(which is important for security), and that noise grows with each
operation (The encrypted result can only be decrypted if the noise
is smaller than $q$, hence using larger values of $q$ imply that
we can do more operations).}

\section{Relinearization}

Remeber we generated another key along with the private and public.
called $ek=\left(ek_{0},ek_{1}\right)$. using this key as randomness
source, we can relinearize the result of multiplication: the new ciphertext
would be :
\begin{align*}
c_{1} & =\left[C_{1}^{*}+ek_{0}\cdot C_{3}^{*}\right]_{q}\\
c_{2} & =\left[C_{2}^{*}+ek_{1}\cdot C_{3}^{*}\right]_{q}
\end{align*}
Remember, decryption is : $c_{1}+c_{2}\cdot sk$. After doing that,
the decryption would result with: 
\[
C_{1}^{*}+C_{2}^{*}\cdot sk+C_{3}^{*}\cdot sk^{2}+C_{3}^{*}\cdot e
\]
 which would decrypt just fine, but with a big error $\left(C_{3}^{*}e\right)$!
We can fix that by using base decomposition.


\section{Base Decomposition}
\section{Mod Switching}

\section{Choosing Parameters}


\chapter{Secret sharing, distributed key generation and threshold cryptography}
\section{Shamir secret sharing}
Given a secret $S$, generate random polynomial 
$p = S + a_0\cdot x + a_1\cdot x+a_2\cdot x^2+\dots$ of degree $f+1$.
create shares $(p(1),p(2),\dots, p(n))$ where $n\ge f+1$ and send it to nodes $(1,2,...n)$.
The nodes will publish their shares when they want to reconstruct the secret.
Using Lagrange interpolation and $f+1$ shares, one can reconstruct the polynomial $p(0)=S$ to learn the secret.

\section{Verifiable secret sharing}
The dealer will generate a random polynomial $P(x)=S+a_1\cdot x +a_2\cdot x^2 +\dots a_n\cdot x^n$. 
It'll broadcast the polynomial as follows: $\{g^{a_i} | i\in [n]\cup {S}\}$.
Then it'll send to each node $i$ its share of the polynomial $P(i)$. 
To verify any share, including shares of other nodes, compute the following: 
$$ g^{P(i)} =
 g^{S}\cdot (g^{a_1})^{i} \cdot (g^{a_2})^{i^2}\cdots  =
 \prod_{j=0}^{k} (g^{a_j})^{i^j} = 
 g^{\sum_{j=0}^{t} a_j \cdot i^j} = 
 g^{P(i)} $$

Every node can compute for any $i$ the value $g^{P(i)}$ using the hidden coefficient broadcasted by the dealer.  
The ability to compute $g^{P(i)}$ guarantees that no one can publish a corrupt share and fool other nodes when they reconstruct the secret.


\section{Distributed key generation}
\subsection{protocol}
Assumptions, $n$ players, where each player has a broadcast channel (Might cost $n^2$ to publish through) and
a private channel to the other players.
Note: I'll use player/ member interchangeably.
\begin{enumerate}
  \item Each member performs VSS.
  That is, player $i$ generates a random polynomial 
  $p_{i}(x)=a_0+a_1\cdot x +a_2\cdot x^2 +\dots a_t\cdot x^t$, and broadcasts $ \{g^{a_i} | i \in [t]\}$.
  Then it sends a private share $ p_{i}(j)$ to each player $j$ where $j>0$.
  \item Each member verifies the share it receives according to the VSS protocol.
  \item Each member $j$ takes the shares it received $\{p_{1}(j),p_{2}(j),\dots\}$ and adds them together. 
  Then publish $ g^{y_i}=g^{\sum_{i}{p_{i}(j)}}$.
  \item Each member verifies these shares. How? They take all the broadcasted values from the first step
  as follows:$ \{g^{a_{ij}} | i \in [t], j \in Players\}$ and compute:
  $$\{\prod_{j}{ g^{a_{1j}}}, \prod_{j}{ g^{a_{2j}}},\dots\}=$$
  $$\{ g^{\sum_{j}{a_{1j}}}, g^{\sum_{j}{a_{2j}}}\} $$ 
  Each member should be able to verify the share their peers sent using these values.
  Denote $\mathcal{Q}$ the distributed polynomial.
  Example:$$g^{\mathcal{Q}(k)}=\prod_{i}(g^{\sum_{j}{a_{ij}}})^{k^i}= g^{\sum_{i}{p_i(k)}}=g^{y_k}$$
\end{enumerate}
\subsection{complexity}
\paragraph{Communication complexity} varies with the costs of broadcasting. using reliable broadcast means
Each of these broadcasts costs $O(n^2)$. with up to constant rounds of broadcasting,
 we get $O(n^3)$ total communication costs in the system. 
 Without reliable broadcast - $O(n^2)$ communication costs
 \paragraph{Computation complexity.} The top computation cost is creating $\mathcal{Q}$ then verifying each value.
 That is, computing $ \{ g^{\sum_{j}{a_{1j}}}, g^{\sum_{j}{a_{2j}}},\dots\} $  is $O(n^2)$, and computing it for each player: $O(n^3)$ 


\section{Largange interpolation in the exponent} %https://crypto.stackexchange.com/questions/67500/how-to-apply-lagrange-interpolation-on-bilinear-pairings
We can modify cryptographic schemes using Lagrange interpolation to work with $f<n$ participants.

Given a dataset of coordinate pairs $(x_j,y_j)$ on 
a polynomial $P(X)=\sum_{i=0}^{k}{a_i^{i}\cdot x^k}$ we can interpolate it as follows:
 $$P(X)=L(x)=\sum _{j=0}^{k}y_{j}\ell _{j}(x)$$
 where $\ell _{j}(x)$ is:

 $$\prod_{0\leq m\leq k, \ m\neq j}\frac {x-x_{m}}{x_{j}-x_{m}}$$
That is, we ensure $L(x_j)=y_j$.

\subsection{Using it in crypto}
For our convinicece, we publish onlt shares of the form: $\{(i,P(i))| i > 0\}$.

Denote: $i_j\in T\subseteq [n]$,  means index of player $j$.
in order to reconstruct we'll need enough indices such that $|T|=deg(P)+1$.

So to evaluate $L(0)$ we'll need to compute for each $i_j\in T$:
$$
 \ell_{i_j}(0) = \frac{
 \prod _{k\in T \setminus \{i_j\}}{\textbf{0}-k}
}{
  \prod_{k\in T \setminus \{i_j\}}{ (i_j - k)}
}
$$
Now, let us finally evaluate the secret:
$$ L(0) = \sum_{i_j \in T} {\ell_{i_j}\cdot P(i_j)} $$


\subsubsection*{$n-out-of-n$ protocol}
We'll take a complex and unfamiliar example to ensure one can apply it to other schemes.
NOTE: We rely in the following example on pairing-based cryptography. 
It'll have slight differences. 
for example, using the key pair $(sk, g^{sk})$ one can sign a message $m$ as follows: $H(m)^{sk}$.

Let's begin:


A node can publish a secret tied to a specific ID in the following protocol (Assume we have pairings).
Each user has a key pair $(sk_{i}, pk_{i})$, 
and the shared public key would be $\prod_{i}pk_{i}=pk$.
that is $\prod_{i}g^{sk_{i}}=g^{\sum_{i}sk_{i}}$.


to hide a new transaction $tx$: sample new keys: 
$\left(sk',pk'\right)$ and a random number $r$.
\begin{itemize}
\item compute $\gamma=Enc_{pk'}\left(tx\right)$
\item compute $c=\left(\underbrace{g^{r}}_{c_{L}},\underbrace{e\left(pk,H\left(\gamma\right)^{r}\right)\cdot sk'}_{c_{R}}\right)$ 
\item send $\left(c,\gamma,pk'\right)$.
\end{itemize}


Now, when every server signs: $\sigma_{i}=H\left(\gamma\right)^{sk_{i}}$\\
we can compute the product signature: $\sigma=\prod H\left(\gamma\right)^{sk_{i}}$
which can be used to decrypt the temp secret key: 
\begin{align*}
 & \frac{c_{R}}{e\left(c_{L},\sigma\right)}=\frac{e\left(g^{x},H\left(\gamma\right)^{r}\right)sk'}{e\left(g^{r},\sigma\right)}=\\
 & =\frac{e\left(g^{\sum sk_{i}},H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g^{r},H\left(\gamma\right)^{\sum sk_{i}}\right)}=\\
 & =\frac{e\left(g^{\sum sk_{i}},H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g,H\left(\gamma\right)\right)^{r\cdot\sum sk_{i}}}=\\
 & =\frac{e\left(g,H\left(\gamma\right)\right)^{r\sum sk_{i}}\cdot sk'}{e\left(g,H\left(\gamma\right)\right)^{r\cdot\sum sk_{i}}}=\\
 & =sk'
\end{align*}
 we managed to find out the temp secret key. now we can get the value
under $\gamma=Enc_{pk'}\left(tx\right)$.


\subsubsection*{$f-out-of-n$ protocol}
We assume all nodes have shares of the same polynomial $P$.
This protocol will have slight changes from the one described before.
It'll ensure we need only $f-out-of-n$ signatures to reconstruct the secret.


Each player holds a share $s_j$ (and a matching public key $g^{s_j}$), generated from Polynomial $P$. 
The shared secret key is $P(0)= S = \sum_{k \in T}{\ell_k(0)\cdot s_k}$,
and the public key is 
$$
  PK=
  \prod_{k\in T}{(g^{s_k})^{\ell_k(0)}} =
  g^{\sum_{k\in T}{\ell_k(0)\cdot s_k}} =
  g^{L(0)}=g^{P(0)}=g^S 
$$
for $|T|=f+1$ indices.

\paragraph*{Creating new secret}
For each transaction $tx$: sample new keys: $\left(sk'\right)$ and a random number $r$.
\begin{itemize}
\item compute $\gamma=Enc_{sk'}\left(tx\right)$
\item compute $c=\left(\underbrace{g^{r}}_{c_{L}},\underbrace{e\left(PK, H\left(\gamma\right)^{r}\right)\cdot sk'}_{c_{R}}\right)$ 
\item send $\left(c, \gamma\right)$.
\end{itemize}



\paragraph*{reconstruction}


With $f+1$ signatures over $H(\gamma)$, we can recompute the secret and extract out of $c$ the decryption key $sk'$.
When a player receives a signature $\sigma_{i}=H\left(\gamma\right)^{s_{i}}$
It verifies the signature and then stores $ (\sigma_i)^{\ell_i(0)}$.
With enough signatures, we can compute the product signature: $$
\sigma=\prod_{k\in T}{\sigma_k^{\ell_k(0)}} = 
\prod_{k\in T}{H\left(\gamma\right)^{\ell_k(0)\cdot s_{k}}} = 
H\left(\gamma\right)^{\sum_{k\in T}{\ell_k(0)\cdot s_{k}}}=
H\left(\gamma\right)^{L(0)} =
H\left(\gamma\right)^{S}
$$
Which can be used to decrypt the temp secret key: 
\begin{align*}
 & \frac{c_{R}}{e\left(c_{L},\sigma\right)}=\frac{e\left(PK, H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g^{r},\sigma\right)}=\\
 & =\frac{e\left(g^S, H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g^{r},H(\gamma)^S\right)}=\\
 & =\frac{e\left(g^S, H\left(\gamma\right)^{r}\right)}{e\left(g^{r},H(\gamma)^S\right)} \cdot sk'=\\
 & =\frac{e\left(g, H\left(\gamma\right)\right)^{S\cdot r}}{e\left(g,H(\gamma)\right)^{r\cdot S}} \cdot sk'=\\
 & =sk'
\end{align*}
 we managed to find out the temp secret key. now we can get the value
under $\gamma=Enc_{pk'}\left(tx\right)$. as wanted.

\chapter{protocols for identification and login}
\section{Identification Protocols}.

\subsection{Types of adversaries}

The identification protocol is a set of a prover $P$ and a verifier
$V$. where the prover wants to gain access to some resource, and
to do so, the verifier must give it access. the verifier will only
give access to a prover that convinces it that it has the rights to
that resource. for example, $P$ wants to enter its house, and to
do so it must unlock the door. the convincing method is a key.
\begin{description}
\item [{Direct$\,\,$attacks}] The adversary is not able to eavesdrop.
Then using no information other than what is publicly avail- able,
the adversary must somehow impersonate the prover to the verifier.
A simple password protocol is sufficient to defend against such direct
attacks.
\item [{Eavesdropping$\:$attacks}] The adversary can eavesdrop and obtain
the transcript of several interactions between the prover and verifier.
In this case the simple password protocol is insecure. However, a
slightly more sophisticated protocol based on one-time passwords (TBD)
is secure.
\item [{Active$\:$attacks}] an active adversary that interacts with the
prover. The adversary uses the interaction to try and learn something
that will let it later impersonate the prover to the verifier. Identification
protocols secure against such active attacks require interaction between
the prover and verifier. They use a technique called challenge-response.
\end{description}

\subsection{Salting}

\paragraph{Storing the password in plaintext is prone to active attacks, once
the verifier is compromised, the adversary can gain access easily.
A simple solution would be to hash the plain-texts. unfortunately
the space of possible passwords being used is not very large. Hence
in addition to hashing the plain-texts, add salt! }

\paragraph{To salt a plain-text, the verifier should add some random string
to it, then store the salt as plain-text, and hash the password and
the salt concat to it ($salt,Hash\left(salt||password\right)$).}

\paragraph{Salting ensures a direct attack would need to run an exhaustive search
over $D\times S$ where $D$ is the dictionary with all weak passwords
and $S$ is the space of random strings the verifier uses, for example
salt size can be $|S|=2^{128}$. }

\paragraph{That is not really the case though, it just ensures the attacker
cannot use a preprocessing algorithm to have efficient attacks. (?the
attacker needs to make a preprocess for all salts it saw in the server
along with the dictionary.) \protect \\
Now its best case would be to run on a dict along hash the plaintext
hash with the word from the dict in the hopes of finding a similar
hash in the servers password file.}

\subsubsection{salt and pepper}

skipped it

\subsection{eavesdrop safe}

\subsubsection{Hotp}

HOTP is a protocol for identification which is safe against eavesdrop
attacks. 

\paragraph{This attack attempts to change the password after each use. To do
so, the prover and verifier should share a secret, which they will
then be used to generate some proof of authenticity. Using $HMAC$
(or a $PRF$ as follows $F\left(k,i\right)$) the prover generates
a new value over a shared counter: $Hmac\left(i\right)$ and will
send it to the verifier. verifier can authenticate it. and then they
both advance $i$ by $1$. }
\begin{rem}
We can improve it by sending both $i$ and the output of the $HMAC$
over $i$, this way the verifier can check if $i$ is greater than
its counter $i'$, so they do not have to be matching counters at
all times.
\end{rem}

\begin{rem}
This verification protocol changes state only upon an attempt to login.
A user that does not login frequently, might be compromised if an
attacker gained the latest token. The attacker can sell the obtain
token to anyone which should give access once unless the user logins
again. 
\end{rem}


\subsubsection{TOPT: time base OTP }

Instead of a counter, one can use the current time, and each login
attempt is only valid if the timestamp is recent enough, say 10 seconds.

\subsubsection{S/key }

TODO.

attempts to solve the leaking key issue: \\
generate random $k$, give the verifier $H^{(n+1)}(k)$. the prover
stores $(k,n)$ to send identification request: 
\begin{itemize}
\item $P$ sends $t=H^{i}(k)$ then sets $i=i-1$. 
\item $V$ will inspect that $H(t)$ equals to what it stored, if it does
it updates the storage as $t$.
\end{itemize}
this can be used for $n$ times, afterwards needs to be regenerated.
kinda cool. 

basically, the provers sends $H^{n}(k)$ then $H^{n-1}\left(k\right)$
... $H(k)$.
\begin{itemize}
\item Assumes that the key is kept secret by the client
\item the resulting password is at least 128bit, which is long to type by
humans. 
\end{itemize}
%
You reached 18.6 in the book, which is talking about security against
active attacks. 

\section{Active attack}

the attacker can impersonate the verifier for a brief moment, and
its goal is to find a secret to fool the actual verifier. 

thus HOTP is easy to break, gain a legit one time password and forward
it to the verification protocol. 

\subsection{challenge-response protocol: }

the verifier sends a random challenge $c$, the prover uses a mac
over the challenge $c$ and send it back. the attacker can only interact
with the prover, it cannot prepare ask the prover all possible challenges
the verifier will chuck at him. and because we use $MAC$ the attacker
cannot forge a response from the prover. 

\subsubsection{improvement }

to ensure the verifier can be compromised and the attacker can't do
anything to gain access later using active attack - we use signature
scheme instead of mac. 

\chapter{Identification and signatures from sigma protocols}

This chapter will be useful to develop zero--knowledge proofs.

\section{Schnorr\textquoteright s identification protocol }

\paragraph{Schnorr's identification protocol is a basic block for building signature
schemes with DH assumption as its base.}

This will be our first proof of knowledge ever to be seen.

\paragraph{This protocol can be proved secure against eavesdropping attacks,
assuming the discrete logarithm problem is hard.}

Let $\G$ be a cyclic group of prime order $q$with a generator $g\in\G$.
Suppose the prover has a secret key $\alpha\in\Z_{q}$ and a corresponding
public key $u=g^{\alpha}$. $P$ wishes to prove to an identifier
$V$ that it knows $\alpha$.

\subsubsection{protocol}

both the prover and the verifier generates random numbers respectively
$k,c$. The prover send $g^{k}$ and once it receives the challenge
$c$ from the verifier, it'll need to compute $t=k+\alpha\cdot c$
and send $t$ to the verifier. in turn, the verifier should compute
the following:$\left(u\right)^{c}\cdot g^{k}=g^{k+\alpha\cdot c}$
which should be equal to $g^{t}$.

\paragraph{A keen eye could see that this is very similar already to Schnorr's
signature scheme.}

\subsubsection{Honest verifier zero knowledge and security against eavesdropping}

We prover that the protocol is eavesdrop safe by assuming the adversary
has access to $vk$, and that it had seen a conversation between $P$
and $V$. The idea is to show that these conversations do not help
the adversary, because the adversary could have efficiently generated
these conversations by himself, given $vk$ (but not $sk$).
\begin{defn}
Let $\mathcal{I}=(G,P,V)$ be an identification protocol. We say that
$\mathcal{I}$ is honest verifier zero knowledge, or $HVZK$ for short,
if there exists an efficient probabilistic algorithm $Sim$ (called
a simulator) such that for all possible outputs $(vk,sk)$ of $G$,
the output distribution of $Sim$ on input $vk$ is identical to the
distribution of a transcript of a conversation between $P$ (on input
$sk$) and V (on input $vk$).
\end{defn}


\paragraph{Comments on the terminology are in order. The term \textquotedblleft zero
knowledge\textquotedblright{} is meant to suggest that an adversary
learns nothing from $P$, because an adversary can simulate conversations
on his own (using the algorithm $Sim$), without knowing $sk$. The
term \textquotedblleft honest verifier\textquotedblright{} conveys
the fact this simulation only works for conversations between $P$
and the actual, \textquotedblleft honest\textquotedblright{} verifier
$V$ , and not some arbitrary, \textquotedblleft dishonest\textquotedblright{}
verifier, such as may arise in an \textbf{active attack} on the identification.}
\begin{thm}
If an identification protocol $\mathcal{I}$ is secure against direct
attacks, and is HVZK, then it is secure against eavesdropping attacks. 
\end{thm}
The main idea here: if I'm secure against someone interacting maliciously with the verifier.
and in addition to that, my regular protocol does not provide any useful information someone
can use later on: im safe against eavsedrop attacks too.

Schnorr's protocol is HVZK, they prove it using a simulator.
In addition to that, they show it's safe against direct attacks by showing that 
if there was some attacker that can break it, it can generate twice accepting answers
to the verifier.
then they can use these two answers to BREAK the discrete log assumption.


\subsection{ECDSA }

The ECDSA signature scheme $(G,S,V)$ uses the group of points $\G$
of an elliptic curve over a finite field $F_{p}$. Let $g$ be a generator
of $\G$ and let $q$ be the order of the group $\G$, which we assume
is prime. Im skipping the algorithm, because it isn't as elegant.
in addition to that, Schnorr sigs are strongly secure, but ECDSA are
not. Given an ECDSA signature $\sigma=\left(r,s\right)$ on a message
$m$, anyone can generate more signatures on $m$.


\section{Sigma protocols: basic definitions }

Schnorr\textquoteright s identification protocol is a special case
of an incredibly useful class of protocols called Sigma protocols.
We'll soon see the basic concepts associated with Sigma protocols
and how they can become helpful to us.\\
Later we'll see how Sigma protocols are useful to us, even out of
the context of identification and signatures.
\begin{defn}
(Effective relation). An effective relation is a binary relation $R\subseteq X\times Y$,
where $X,Y$ and $R$ are efficiently recognizable finite sets. Elements
of $Y$ are called \textbf{statements}. If $\left(x,y\right)\in R$,
then $x$ is called a witness for $y$.
\end{defn}

\begin{defn}
Sigma Protocol. Let $R\subseteq X\times Y$ be an effective relation.
A \textbf{Sigma Protocol }for $R$ is a pair $\left(P,V\right)$.
\begin{itemize}
\item $P$ is an interactive protocol algorithm called the \textbf{prover},
which takes as input a witness--statement pair $\left(x,y\right)\in R$.
\item $V$ is an interactive protocol algorithm called the \textbf{verifier},
which takes as input a statement $y\in Y$, and which outputs accept
or reject.
\item $P$ and $V$ are structured so that an interaction between them always
works as follows:
\begin{itemize}
\item To start the protocol, $P$ computes a message $t$, called the commitment,
and sends $t$ to $V$;
\item Upon receiving $P$\textquoteright s commitment $t$, $V$ chooses
a challenge $c$ at random from a finite challenge space $C$, and
sends $c$ to $P$;
\item Upon receiving $V$ \textquoteright s challenge $c$, $P$ computes
a response $z$, and sends $z$ to $V$;
\item Upon receiving $P$\textquoteright s response $z$, $V$ outputs either
\textbf{accept} or \textbf{reject}, which must be computed strictly
as a function of the statement $y$ and the conversation $\left(t,c,z\right)$.
In particular, $V$ does not make any random choices other than the
selection of the challenge --- all other computations are completely
deterministic.
\end{itemize}
\end{itemize}
We require that for all $\left(x,y\right)\in R$, when $P\left(x,y\right)$
and $V\left(y\right)$ interact with each other, $V\left(y\right)$
always outputs accept.
\end{defn}

\begin{rem}
So a sigma protocol, is any prover verifier challenge where the prover
knows some witness to y and want to prove that $y$ is in the language
to the verifier?
\end{rem}

If the output is accept we call the conversation $\left(t,c,z\right)$
an accepting conversation for $y$.
\begin{example}
It should be clear that for Schnorr\textquoteright s identification
protocol $\left(G,P,V\right)$, the pair $\left(P,V\right)$ is an
example of a \textbf{Sigma protocol} for the relation $R\subseteq X\times Y$,
where
\[
X=\Z_{q},Y=\G\text{ and }R=\left\{ \left(\alpha,g^{\alpha}\right)\in\Z\times\G\right\} .
\]

TODO continue
\end{example}


\chapter{MPC}
We have a function f that takes n inputs and produces m outputs:
$$  (y_1,...,y_m) = f(x_1,...,x_n).$$
We also have N parties, $P_1,...,P_N$. 
Their goal is to run a protocol where each input value $x_i$ is 
contributed by one of the parties and each output $y_j$ is obtained by one or more of
 the parties.


We want to design an efficient protocol for this problem that provides
\emph{ privacy, soundness, and input independence}.

\section{Wanted properties}
\begin{itemize}
  \item Privacy: No part learns anything about any other part's inputs
  (except for the information that is inherently revealed by the outputs).
  \item Soundness/correctness: honest parties compute correct outputs. 
  \item Input independence: All parties must choose their 
  inputs independently of the other parties' inputs 
  (No one can use Alice's inputs to their advantage).
  \item Guaranteed output delivery: all honest parties are guaranteed to obtain
  their output.
  \item Fairness: If any party (including corrupted members) obtains their output, 
  then all honest parties do so.
\end{itemize}
\section{Formal Security}
The way to define security formally is to say that an attack on the protocol in 
the "real world" 
is equivalent to some attack on the protocol in an "ideal world" in which 
no damage can be done.

In the ideal world, the protocol is implemented using a trusted 
party to which all parties (both honest and corrupt) submit inputs, 
and from which all parties (both honest and corrupt) obtain their designated outputs. 
The trusted party itself cannot be corrupted.

We then describe the details of the ideal-world execution, including the 
behavior of the trusted party who evaluates the function.

The definition of security then basically says: for every efficient adversary $A$ 
in the real world, there exists an "equivalent" efficient 
adversary $\mathcal{S}$ in the ideal world (usually called a simulator).
Since there is no possible attack in the ideal world, 
there is no possible attack in the real world.

the informal notions of \emph{privacy, soundness, and input independence} are
 implied by this type of definition.

 Essentially we'll want to show that the ideal world we describe is 
 "equivalent" to the real world.

 \subsection{A few applications of MPC}
 \begin{itemize}
  \item Elections: Without MPC, parties submit votes to a trusted server $T$ who 
  counts the votes and states the winner.
  \item Privacy-preserving mining of medical data. Two hospitals want to share data,
  to perform research, but cannot share it due to regulations.

 \end{itemize}

\section{Securely evaluating arithmetic circuits}

