
\chapter{Distributed Algorithms}

Many thanks to the Decentralized thoughts blog.

\paragraph{cheat sheet: https://decentralizedthoughts.github.io/2021-10-29-consensus-cheat-sheet/}

\section{Basic Foundations and Classics}

\subsection{Consensus and Agreement}

In this section, we define the consensus problem and discuss some
variants and their differences.

\paragraph{Let us begin with the most straightforward consensus problem: agreement.}

\subsubsection{The agreement problem}

\paragraph{We assume $n$ nodes, where each node $i$ has some input $v_{i}\in V$
where $V$ is the set of all possible values. A protocol that solves Agreement must have the following properties:}
\begin{enumerate}
\item $\left(Agreement\right)$: no two honest nodes \textbf{decide} on
different values.
\item $\left(validity\right)$: if all honest nodes have the same input
value $v$, then $v$ must be the decision value.
\item $\left(termination\right)$: all honest nodes must decide on a value
from $V$ and terminate.
\end{enumerate}
\begin{itemize}
\item This is a strong property. that is, validity guarantees that a decisional
value must be held by all honest nodes.
\item We can make the agreement property even stronger - no two nodes (notice
I've omitted the honest?) decide on different values.
\end{itemize}
%

\paragraph{We continue to another consensus problem tied strongly
with the agreement problem.}

\subsubsection{Broadcast problem}

We assume a designated node, the leader, holds some value $v\in V$.
A protocol that solves Broadcast must comply with the following properties:
\begin{enumerate}
\item $\left(Agreement\right)$: no two honest nodes \textbf{decide} on
different values.
\item $\left(validity\right)$: if the leader is honest then $v$ must be
the decision value.
\item $\left(termination\right)$: all honest nodes must decide on a value
from $V$ and terminate.
\end{enumerate}
\begin{xca}
Implement Broadcast given a black box Agreement protocol.
\end{xca}

\begin{sol}
$ $

My Assumptions: the leader is known. Can communicate privately on a secure
channel with each server.
\begin{enumerate}
\item first round; the leader chose a value and send it to all.
\begin{enumerate}
\item an honest machine would only accept a value from the leader, and once.
\end{enumerate}
\item second round; every honest node should hold the same value as the
leader, so they can now start to run the agreement protocol.
\item end of the agreement should mean all had a decision, and because all held
the value $v$ that the leader sent, this is the agreement value.
\end{enumerate}
proving the properties is immediate from definitions. Termination
from the agreement protocol. Agreement from agreement protocol. Validity
is because the leader is honest and did not send different values
to the servers, and then the agreement kicked off with the same input
values.
\end{sol}

\begin{xca}
Implement Agreement using broadcast.

Note, in this exercise you start with $n$ leaders. how would you
make an agreement protocol?
\end{xca}


\section{Synchrony, Asynchrony, and Partial synchrony }

\paragraph{In the standard model, communication uncertainty is captured by an
adversary that can delay messages. }

The three basic communication models are: 
\begin{description}
\item [{synchronous}] There exists some known finite time bound $\Delta$.
For any message sent, the adversary can delay its delivery by at most
$\Delta$.
\item [{Asynchronous}] for any message sent, the adversary can delay its
delivery by any finite amount of time. So, on the one hand, there
is no bound on the time to deliver a message, but each message must eventually be delivered.
\item [{partial--synchrony}] This is a combination of the two. In
this model, we assume that there exists some known finite time $\Delta$,
and a special event called GST (global stabilization time) such that:
\begin{itemize}
\item the adversary must cause the GST event to happen after some unknown
finite time.
\item any message that is sent at time $x$ must be delivered by time $\Delta+\max\left(x,GST\right)$.
\end{itemize}
Another definition: Partial synchrony is to assume that there is some
finite unknown upper bound \textgreek{D} on message delivery. This
bound is not known in advance and can be chosen by the adversary.
\end{description}

\paragraph{Partial synchrony captures the intuition that we would like to design
protocols for systems that are usually synchronous but have reasonable
guarantees, even if the synchrony assumptions become temporarily violated
by some extreme event (like a denial of service attack). In particular,
a recurring theme in the Partial synchrony model is to design protocols
that are always safe (even when the system is asynchronous) but provide
liveness and termination guarantees only after GST (only when the system is synchronous).}

\section{The Threshold Adversary}

If the adversary has no limits, then there is very little we can do.
The simplest model is that of a threshold adversary. Given $n$ nodes,
the adversary controls some $f$ nodes.
\begin{enumerate}
\item $n>f$, the adversary controls all but one.
\item $n>2f$, the adversary controls a minority of nodes, often called
the dishonest minority.
\item $n>3f$, where the adversary controls less than a third of the nodes.
\end{enumerate}
%

\section{Generalized bounded resource threshold adversary }

The adversary control some fraction of the resources.
\begin{enumerate}
\item the adversary controls any fraction of the resource, but not all.
\item the adversary controls $\frac{1}{2}-\epsilon$ fraction of the resource. 
\item the adversary controls less than $\frac{1}{3}$ fraction of the resource.
\end{enumerate}
%
Some common examples:
\begin{enumerate}
\item in Nakamoto consensus, the adversary has access to $\frac{1}{2}-\epsilon$
fraction of CPU power.
\item in systems that use proof-of-stake, the assumption is that the bounded
resource is some finite set of coins. It is then natural to assume
that the adversary controls a threshold of the total coins. can
often map voting power based on the relative amount of coins at a
given time. For example, Algorand mentions the total voting power
of the adversary is bounded by a third.
\end{enumerate}
%

\subsection{A note on stake-based bounded resources }
\begin{enumerate}
\item On the one hand, using a resource controlled by the platform
allows controlling the resource allocation in ways that are not possible
when the resource is external. In particular, the platform can create
punishment mechanisms to incentivize honest behavior better. For
example, Buterin suggests conditions to detect malicious behavior
and punish the adversary by reducing (slashing) the offender\textquoteright s
stake. 
\item n the other hand, if the value of the stake depends on the platform,
this may cause some circular reasoning about security and in particular
a bootstrapping problem. If the value of the total coins is too high,
then it may happen that not enough honest entities will sign up and
the system will lose liveness. If the value of the total coins is
initially too low, then an attacker can gain early monopoly power.
One option is to bootstrap proof-of-stake using an existing decentralized
high-value Proof-of-work coin or high-value traditional fiat (see
here). This type of solution assumes that the adversary does not already
have monopoly power on the bootstrapping resource. Another option
is to bootstrap a Proof-of-stake system from an existing high-value
Proof-of-work system (for example, see eth2.0).
\end{enumerate}

\section{The power of the adversary }

We still need to make important modeling decisions about the adversary
power. In addition to the size of the threshold ($n>f,n>2f,\text{or }n>3f$
), there are 4 more important parameters:
\begin{enumerate}
\item The type of corruption.
\item The computational power of the adversary.
\item The visibility of the adversary. (TBD).
\item The adaptivity of the adversary.
\end{enumerate}

\subsection{Type of corruption}

\paragraph{There are four classic adversaries: Passive, Crash, Omission, and
Byzantine.}
\begin{description}
\item [{Passive}] Also known as Honest-but-curios. Will follow the protocol
in earnest, but allows the adversary to learn any information in its
$view$.
\item [{Crash}] Once corrupted, it'll stop sending or receiving messages.
\item [{Omission}] Does not deviate from the protocol, but will lose or
wont send messages according to the adversaries will.
\item [{Byzantine}] this gives the adversary full power to control the
party and take any (arbitrary) action on the corrupted party.
\end{description}
\begin{rem}
Each level of corruption, subsumes the previous level.
\end{rem}

\begin{rem}
There are more types of corruptions, which we'll investigate later.
\end{rem}


\subsection{Computational power}
\begin{description}
\item [{Unbounded}] the adversary has unbounded computational power. This
model often leads to notions of perfect security or statistical security.
\item [{Computationally-bounded}] the adversary is at most a polynomial
advantage in computational power over the honest parties. Typically
this means that the adversary cannot (except with negligible probability)
break the cryptographic primitives being used. For example, typically
assume the adversary cannot forge signatures of parties not in its
control.
\item [{Fine-grained$\,\,$computationally--bounded}] there is some concrete
measure of computational power and the adversary is limited in a concrete
manner. This model is used in proof-of-work based protocols.
\end{description}

\subsection{Visibility}

\paragraph{The visibility is the power of the adversary to see the messages
and the states of the non-corrupted parties. Again, there are two
basic variant:}
\begin{description}
\item [{Full$\,\,$information}] here we assume the adversary sees the
internal state of all parties and the content of all message sent.
This often limits the protocol designer. See for example: Feige\textquoteright s
selection protocols, or Ben-Or et al\textquoteright s Byzantine agreement. 
\item [{Private$\,\,$channels}] in this model, we assume the adversary
cannot see the internal state of honest parties and cannot see the
internal content of messages between honest parties. The adversary
does know when a message is being sent and depending on the communication
model can decide to delay it by any value that is allowed by the communication
model.
\end{description}
In round based protocols:
\begin{description}
\item [{Rush}] the adversary can see all messages in a round before choosing
what to send.
\item [{non-Rush}] the adversary must commit to the round $i$ messages
it sends before it receives any round $i$ messages from non-faulty
parties.
\end{description}

\subsection{Adaptivity }

\paragraph{Adaptivity is the ability of the adversary to corrupt dynamically
based on information the adversary learns during the execution. There
are three basic variants: static, adaptive, and mobile. The adaptive
model has several sub-variant. We will cover here only the simplest
one.}
\begin{description}
\item [{Static}] the adversary has to decide which $f$ parties to corrupt
before executing the protocol.
\item [{Adaptive}] the adversary can decide dynamically as the protocol
progresses who to corrupt based on what the adversary learns over
time. The main parameter still needs to be decided on how long
it takes between the adversary's decision to corrupt and the event that
the control is passed to the adversary. One standard assumption is
that this is instantaneous. Another is that it takes an additional
round.
\item [{Mobile}] the adversary can decide dynamically who to corrupt and
who to un-corrupt. The number of corrupted parties at any given
time is at most $f$, but the set of corrupted parties
may change over time. It is often required that there is a gap between the time
the adversary corrupts one party and the time it is allowed to corrupt
another.
\end{description}
%

\section{The Trusted Setup Phase }

When you want to understand a decentralized system, you first need to ask whether it has a trusted setup phase.

\paragraph{Many distributed computing and cryptography protocols require
a trusted setup. A trusted setup is a special case of a multi-phase
protocol. We call the first \textbf{phase} the setup phase and the
second phase the main phase. Two properties often distinguish
a setup phase from the \textbf{main phase}:}
\begin{itemize}
\item Typically, the main phase implements some repeated task. The setup
phase is done once and enables repeating many instances of the main
phase.
\item The setup phase is often input-independent. Namely, it does not use
the private inputs of the parties. Furthermore, sometimes the setup
phase is even function-independent, meaning that the specific function
that the parties wish to compute is irrelevant; the parties at this
phase only know that they want to compute some function. As such,
the setup and main phases are often called offline (or preprocessing)
and online respectively (i.e., parties may run the offline phase when
they realize that at some later point in time, they will want to run
some function on inputs they do not know yet).
\end{itemize}

\paragraph{think of a setup phase as an ideal functionality run by a wholly
trusted entity, denoted T. For instance, assuming Public-Key Infrastructure
(PKI) means that we assume there is a wholly trusted entity to
which every party submits its public encryption (and verification) key,
 and that entity broadcasts those keys to all parties. In this
chapter, we will review some of the common types of trusted setup assumptions
by looking at their ideal functionalities.}

\paragraph{One way to model that trusted entity follows: There is an initial
set of parties $p_{1},\dots,p_{n}$ who interact with the trusted
entity $T$. The parties may send inputs $x_{1},\dots,x_{n}$ to $T$
(where $x_{i}$ is $p_{i}$'s input), who in turn, runs some function
$f\left(r,x_{1},\dots,x_{n}\right)$ where $r$ is a uniformly random
string, obtains outputs $y_{1},\dots,y_{n}$ and hands $y_{i}$ to
$p_{i}$. This process may be \textquotedblleft reactive\textquotedblright ,
namely, it may repeat multiple times. As this already describes an
idealized world, we always assume that the communication channels
between the parties and the trusted entity are secure.}

\paragraph{we argue that most of those functionalities fall into one of out
of the five categories below:}
\begin{enumerate}
\item No Setup: This is the simplest case, in which we don\textquoteright t
really use any trusted entity or any trusted setup. The minimal communication
assumption is that parties have access to some type of communication
medium. Often, though, \textquotedblleft no setup\textquotedblright{}
also refers to a setting where parties\textquoteright{} identities
are globally known.
\item Pairwise setup: Here we assume there is some set of initial parties
$p_{1},\dots,p_{n}$ and each two parties have a reliable communication
channel between them. In particular, in the simplest pairwise setup
assumption when party $p_{i}$ receives a message on the $(i,j)$
channel it knows that party $p_{j}$ sent this message. 
\item Broadcast setup: We assume a setup whose implementation requires no
secrets. The canonical example is a PKI setup that requires broadcast
only to relay the public keys. 
\item Partially public setup: often called the Common Reference String (CRS)
model. Many cryptographic protocols leverage this setup for improved
efficiency. A special case of this setup is a randomness beacon. 
\item Fully private setup: often called the offline phase in the context
of secure multiparty computation (MPC) protocols. Here, the setup
phase computes a rather complex output that is party-dependant.
\end{enumerate}
Let us detail these five setup variants.

\subsection{No Setup }

If a protocol has no setup, then there is nothing to worry about.
It\textquoteright s easier to trust such protocols. On the other hand,
there are inherent limitations.

\paragraph{A setting with no setup has two main flavors. The first assumes really
nothing on the knowledge of the parties and is sometimes called anonymous
channel model The second assumes global knowledge of the identities
of all parties, which is quite acceptable in many real world applications.
Both flavors suffer from non-authenticated channels, meaning that
the adversary can launch man-in-the-middle attacks arbitrarily.}

\paragraph{In traditional cryptography (where the adversary is polynomially-bounded),
this type of model was first studied by Dolev, Dwork and Naor, for
specific tasks like non-malleable encryption and zero-knowledge and
later generalized to arbitrary computations by Barak et al. (The latter
assumes global identities.)}

\paragraph{Another line of research, in the anonymous model, is based on a more
refined assumption on the adversarial power. Namely, the assumption
limits the computational power of the adversary (e.g., hash rate)
compared to the computational power of the honest parties. It was
shown possible to construct a limited notion of PKI from scratch even
in this slim model. }

\subsection{Pairwise Setup}

Here, we assume that the communication channel between every pair
of parties is authenticated. This is a classic assumption in distributed
cryptography and distributed computing. The Fisher, Lynch and Merritt
1985 lower bounds show that even weak forms of Byzantine Agreement
are impossible when $n\le3\cdot f$ even given this setup, and even
against a traditional polynomially-bounded adversary.

\paragraph{For $n>3\cdot f$, on the other hand, this setup allows perfect implementation
of any functionality. This is the celebrated result of Ben-Or, Goldwasser
and Widgerson 1988 (see Asharov and Lindell for a full proof).}

\subsection{TODO: complete from this blogm page: }

https://decentralizedthoughts.github.io/2019-07-19-setup-assumptions/

\section{Broadcast}

todo: https://decentralizedthoughts.github.io/2019-10-22-flavours-of-broadcast/

\section{Sync HotStuff}

A Simple and Practical State Machine Replication.

\chapter{Elliptic curves}
Taken from \emph{A Graduate Course in Applied Cryptography, Dan Boneh and Victor Shoup}

The best-known discrete log algorithm in an elliptic curve group of size $q$ runs in time $O(\sqrt{q})$. 
This means that to provide security comparable to AES-128, it suffices to use a group of size $q \approx 2^{256}$ 
so that the time to compute discrete log is $\sqrt{q} \approx 2^{128}$.

\section{a bit of history on elliptic curves}
Elliptic curves come up naturally in several branches of mathematics.
Here we will follow their development as a branch of arithmetic (the study of rational numbers).
Diophantus, a greek mathematician who lived in Alexandria in the third century, was interested 
in the following problem: Given a bivariate polynomial equation, $f(x,y)=0$ find 
rational points satisfying the equation. That is, find $P=(x,y)$ such that $x,y\in\mathbb{Q}$.
Diophantus wrote a series of influential books on this subject, called the \emph{Arithmetica}, of which six survived.
Much of Arithmathica studies integer and rational solutions of quadratic equations.
For example, one of the first problems in the books regarding elliptic curves is to find $(x,y) \in \Q$
 that satisfy the equation $$ y^{2}=x^3 - x + 9$$
The method invented to answer this question secures most Internet traffic worldwide.
One can easily verify that the following points are on the curve $(0, \pm3), (1, \pm3), (-1, \pm 3)$.
Diophantus developed a method similar to \underline{chord method}:
Given two rational points $U$ and $V$ on the curve, where $U\neq -V$, we can pass a line through them,
 and this line must intersect the curve at a third rational point $W$. 
The chord method was rediscovered several times over the centuries, but it finally stuck with the work of Poincare.

Poincare defines the sum of $U, V$, denoted $U \boxplus V$ as $U \boxplus V := -W$
Diophantus' method, the \emph{tangent method} is another way to build a new rational point from a given rational point. 
We should later see that the method corresponds to adding the point $P$ to itself: $P\boxplus P$.
\section{elliptic curves over finite fields}
We are primarily interested in elliptic curves over finite fields for cryptographic applications.
\begin{defn}
  Let $p >3 $ be a prime. An \textbf{elliptic curve} $E$ defined over $\mathbb{F}_p$ is an 
  equation  
  $$ y^2 = x^3 +ax + b$$
  where $a,b \in \mathbb{F}_p$ satisfy $4a^3 +27b^2 \neq 0$. We write $E/\mathbb{F}_p$ to denote
  the fact that $E$ is defined over $\F_p$.
\end{defn}
The weird condition $4a^3 +27b^2 \neq 0 $ ensures that the equation 
$ x^3 + ax + b = 0$ does not have a double root (needed to avoid degeneracies).

\begin{defn}
  We say that point $P=(x,y)$, where $x,y \in \F_p$, is on curve $E$ if it satisfies the equation of $E$.
\end{defn}
\begin{defn}
  $E(\F)$ denotes the set of all points on the curve E and are defined over $\F$.
\end{defn}

The addition law, and adding to the set $E(F_p)$ the member $\mathcal{O}$,
 which servers as the identity member, turns it into a group. I'm not getting into the addition laws.

\section{Elliptic curve cryptography}
Given two points $P$ and $\alpha \cdot P$, where $\alpha \in \Z_q$, it is hard to compute $\alpha$.
The best known algorithm to compute $\alpha$ is $\Omega(\sqrt{q})$.
There are a few exceptions to these rules, and thus one should be careful when defining a new curve.
So it's better to use some specific already implemented and used curve rather than 
generating a random prime $p$ and a random curve over $\F_p$.
\section{Pairing based cryptography}
We now show that certain elliptic curves have an additional structure,
called a pairing, which enables a world of new schemes that could not be built
 from discrete log groups without this other structure.

 \begin{defn}
  Let $\G_0, \G_1, \G_T$ be three cyclic groups of prime order $q$ where 
  $g_0\in\G_0$ and $g_1\in\G_1$ are generators. A \textbf{pairing} is an efficiently
  computable function $e: \G_0 \times \G_1 \to \G_T$ satisfying the 
  following properties:
  \begin{itemize}
    \item bilinear: $\forall u,u'\in\G_0, v,v'\in\G_1$  we have 
        $$ e(u\cdot u',v) = e(u,v) \cdot e(u',v) and  e(u,v\cdot v') = e(u,v)\cdot e(u,v')$$
    \item non-degenerate: $g_T := e(g_0,g_1)$  is a generator of $\G_T$.
  \end{itemize}
\end{defn}
We refer to $\G_0,\G_1$ as the pairing groups and $\G_T$ as the target group.

Bilinearity implies the following central property of pairing that will be used
in all our constructions: for all $a, b\in \Z_q$ we have
  $$ e(g_0^a,g_1^b)=e(g_0,g_1)^{a\cdot b}= e(g_0^b,g_1^a)$$
This equality follows from the equalities 
$e(g_0^a,g_1^b)=e(g_0,g_1^b)^a=e(g_0^a,g_1^b)=e(g_0^a,g_1)^b$
which are themselves a direct consequence of bilinearity (Note that in cyclic groups
 such as $\G_0 and \G_1$ this definition is equivalent to the definition of bilinearity above).
[if I understand correctly, due to $\G_0 and \G_1$ having generators, we can represent every number
as a power of the generators themselves, and using bilinearity we can reach the above equations]

In a symmetric pairing group, where $G_0 = G_1$ schemes like ElGamal aren't secure anymore,
that is, given two public keys, it is to break the DDH assumption: 
  $$ e(g^x,g^y) = e(g,g)^{x\cdot y}$$ 
Hence, it is possible to extract information. 

In asymmetric pairing, where $G_0 \neq G_1$, it may still be possible
that the DDH assumption holds in both $G_0$ and $G_1$. 

Furthermore, if the discrete log in $G_T$ is easy, it is easy in $G_0$ (and $G_1$).

\begin{rem}
  The pairing function $e$ on an elliptic curve comes from an algebraic pairing called the \textbf{Weil pairing}.
  Which can be efficiently evaluated. In practice, one uses variants of the weil 
  pairing, called the Tate and Ate pairings.
\end{rem}

We'll avoid $bn256$ curve as it isn't secure.


\subsection*{optimisations}
\begin{itemize}
  \item When the first value of the pairing is known, we can speed things up
  by calculating a table of the other possible values. (though it seems very inefficient, and memory intensive.)
\end{itemize}

\section*{The BLS signature scheme}
Let $e:F_0 \times G_1 \to G_T$ be a pairing where $G_0,G_1,G_T$ are
cyclic groups of prime order $q$, and where $g_0\in G_0, g_1\in G_1$ are
generators. 
We'll also require a hash function $H : \mathcal{M} \to G_0$.

The BLS signature scheme denoted $\mathcal{S}_BLS = (G,S,V)$, has message space
$\mathcal{M}$ and works as follows:
\begin{itemize}
  \item $G():$ The key generation algorithm runs as follows 
  $$  \alpha \from \Z_q,u\from g_1^\alpha \in G_1  $$
  The public key is $ pk := u$, and the secret key is $\alpha$.

  \item $S(sk,m):$ To sign a message $m\in \mathcal{M}$ using a secret key
  $sk=\alpha\in\Z_q$ do:
  $$ \sigma\from H(m)^{\alpha} \text{ output } \sigma$$

  \item $V(pk,m,\sigma):$ To verify a signature 
  $$ e(H(m), u) = e(\sigma,g_1) $$
  that is, the signature is accepted due to the following calculations
  $$e(H(m), g_1^\alpha) = e(H(m),g_1)^\alpha = e(H(m)^\alpha,g_1)= 
  e(\sigma, g_1)
  $$
\end{itemize}

\section*{Advanced encryption schemes from pairings}
\subsection*{Identity based encryption}
Using Identity-Based Encryption (IBE from now), Alice can send an encrypted message to Bob
without asking for bobs key beforehand. Beyond key exchange, IBE can also 
be used to construct CPA-secure public key encryption and even search encrypted data.
In an IBE scheme, a trusted entity, Trudy, generates a master key pair $(mpk, msk)$.
The key $mpk$ is the \emph{master public key} and is known to everyone. Trudy keeps the \emph{master 
secret key} $msk$ to herself. When Bob wants to use his email address as his public key, he must
somehow obtain the private key derived from $msk$ and Bob's public key.
We denote Bob's email address as his (public) identity $id$ and denote the corresponding private key 
by $sk_{id}$. He receives $sk_{id}$ by contacting Trudy, she'll use $msk$ and $id$ to generate $sk_{id}$,
and send it back to Bob.
Now anyone, including Alice, can send bob messages without looking up his public key. 
Assuming, of course, that Alice knows $mpk$.

\begin{defn}
  An \textbf{Identiy based encryption scheme $ \mathcal{E}_id =(S,G,E,D)$}
  is a tuple of four efficient algorithms: a \textbf{setup algorithm $S$}, a 
  \textbf{Key generation algorithm $G$}, an \textbf{encryption algorithm $E$}
  and a \textbf{decryption algorithm $D$}.

  \begin{itemize}
    \item $S$ is a probabilistic algorithm which outputs $(mpk, msk) \overset{_R}{\leftarrow} S()$.
    \item $G$ is a probabilistic algorithm invoked as $sk_{id} \getrandom G(msk, id)$.
    \item $E$ is a \emph{probabilistic} algorithm invoked as $c \getrandom E(mpk, id, m)$.
    \item $D$ is a deterministic algorithm invoked as $m\getrandom D(sk_{id},c)$. Where $m$ is
      either a message or a \textbf{reject} value.
    \item We require that decryption undoes encryption: 
    $$ \Pr[D(G(msk,id), E(mpk,id,m))=m]=1$$
    \item identities, messages, and ciphertexts are in their respective finite spaces,
    and $\mathcal{E}_id$ is defined over $(\mathcal{ID},\mathcal{M},\mathcal{C})$.
  \end{itemize}
\end{defn}

We can view IBE as a particular public key encryption scheme where the messages
to be encrypted pairs $(id, m)\in\mathcal{ID\times M}$. The master secret key can
decrypt any well-formed ciphertext. However, there are weaker secret keys, 
such as $sk_{id}$ that can decrypt a ciphertext $c\getrandom E(mpk, id', m)$ only if $id'=id$.


Bob won't use his email address as a public key if a company uses IBE. Otherwise, if Bob's secret key 
is compromised, bob would need to change his email. Instead, Bob's public key
should bob could use the identity string $(id, date)$.
Bob will need to request a new secret key from Trudy every day.
Now Alice can even encrypt emails for specific dates, and bob cannot access it before that, 
unless Trudy gives bob any key he requests.

I will not go into detail about the formal definition of security, but the idea is that
the attacker has access to any $sk_{id'}$ it want but should not be able to break semantic
security for some other identity with secret key $sk_{id}$ that the adversary does not have.


\subsection*{IBE from pairings}
We'll need a few components before being able to construct an IBE: 
\begin{itemize}
  \item a pairing. as defined above, over cyclic groups of prime order $q$, 
  with generators $ g_0, g_1 $.
  \item a symmetric cipher $\mathcal{E}=(E_s,D_s)$.
  \item hash functions $H_0:\mathcal{ID}\to \G_0$ and $H_1:\G_1\times\G_T\to \mathcal{k}$,
  where k is the key space.
\end{itemize}
\subsubsection*{Construction 1}

\begin{itemize}
  \item $S():$ runs as follows:
  $$ \alpha\getrandom \Z_q, u_1\from g^\alpha, mpk \from u_1, msk \from \alpha 
  \text{ output }(mpk,msk) $$
  \item $G(msk,id):$ key generation using $msk = \alpha$:
  $$ sk_id \from H_0(id)^\alpha \in \G_0 \text{ output } sk_id$$
  \item $E(mpk, id, m ):$ encryption using the public parameters $mpk=u_1$:
  \begin{align*}\label{lamlam} 
    \beta \getrandom \Z_q,\  z\from e(H_0(id),mpk^\beta) 
    \\ \ 
    k\from H_1(g^\beta,z), c\getrandom E_s(k,m), \text{ output } (g^\beta,c)
  \end{align*}
  The encryption generates a new secret key $k$ at random. This private key relies on the pairing with
  the hashed public id. Once we've generated the ephemeral secret key $k$, we encrypt the message $m$.

  \item $D(sk_id,(w_1,c)):$ decryption using secret key $sk_id$ of ciphertext $(w_1,c)$:
  \begin{align*}
    z \from  e(sk_{id},w_1), k\from H_1(w_1, z), m\from D_s(k,c),
  \text{ output } m
  \end{align*}
  The decryption relies on $w_1=g^\beta$ to figure out the symmetric encryption key $k$.
  With $k$, the message can be decrypted.
  \newline
  To generate $k$ correctly, we first remind the reader that $$sk=H(id)^\alpha, mpk^\beta=g^{\alpha\beta}, k=H(g^\beta,z)$$
  now, let's compute $z$, our missing component:
  $$
  z=\underbrace{e(sk_{id},g^\beta)}_{\text{z in decryption}}=e(H(id)^\alpha,g^\beta)=e(H(id),g^{\alpha\beta})=\underbrace{e(H(id),mpk^\beta)}_{\text{z in encryption}}
  $$
\end{itemize}



\chapter{Fully Homomorphic Encryption}

TODO; add homomorphic encryption definition. NOTE: they can support
multiple operations.

We can have both a symmetric key HE, or an asymmetric key HE. 

\section{operations}

\paragraph{Some homomorphic encryption schemes, such as BGV, BFV, and CKKS,
support \textquotedblleft packing\textquotedblright{} -- or \textquotedblleft batching\textquotedblright{}
-- many plain-texts into a single cipher-text}
\begin{itemize}
\item we can do logical ops; like AND, OR, XOR
\item addition and multiplication
\item ops over fixed point numbers
\item rotations on packed cipher-texts
\end{itemize}

\section{Hardness}

Most HE schemes are using different Hardness assumptions than DDH.

\paragraph{In plain language, the basic hardness is called Learning with Errors,
and it assumes that no adversary can infer whether $Ax+e=c$ or $Ax=c$
just from seeing $A,c$. the formal definition:}
\begin{defn}
Learning With Errors (LWE) Problem. The LWE problem is parametrized
by four parameters: $\left(n,m,q,\text{\ensuremath{\mx}}\right)$
where $n$ is a positive integer referred to as the \textquotedblleft dimension
parameter\textquotedblright , $m$ is \textquotedblleft the number
of samples\textquotedblright , $q$ is a positive integer referred
to as the \textquotedblleft modulus parameter\textquotedblright{}
and $\mx$ is a probability distribution over rational integers referred
to as the \textquotedblleft error distribution\textquotedblright .
The LWE assumption requires that the following two probability distributions
are computationally indistinguishable: 
\begin{description}
\item [{Distribution~1.}] Choose a uniformly random matrix $m\times n$
matrix $A$, a uniformly random vector $s$ from the vector space
$\Z_{q}^{n}$, and a vector $e$ from $\Z^{m}$ where each coordinate
is chosen from the error distribution $\mx$. Compute $c:=As+e$,
where all computations are carried out modulo $q$. Output $\left(A,c\right)$. 
\item [{Distribution~2.}] Choose a uniformly random $m\times n$ matrix
$A$, and a uniformly random vector $c$ from $\Z_{q}^{m}$ . Output
$\left(A,c\right)$. 
\end{description}

\paragraph{The error distribution $\protect\mx$ can be either a discrete Gaussian
distribution over the integers, a continuous Gaussian distribution
rounded to the nearest integer, or other distributions supported on
small integers.}
\end{defn}


\section{The BGV and BFV Encryption schemes}

BFV is instantiated over two rings:
\begin{enumerate}
\item The plaintext ring which includes encodings of unencrypted or intelligible
messages;
\item The ciphertext ring which includes encrypted messages.
\end{enumerate}
Similar to any other FHE scheme, BFV allows an untrusted party to
induce meaningful computation over en- crypted data without access
to the decryption key.

\subsection{BFV Primitives}

The scheme consists of numerous algorithms:
\begin{itemize}
\item $ParamGen(\lambda)\to Params$ : Parameter generator (ParamGen) takes
as input the security parameter $\lambda$, which is a number used
to define the security level of BFV, and returns a set of encryption
parameters used in BFV. One can view $\lambda$ as the computational
cost of successful attacks on the scheme. In order for these attacks
to succeed with probability 1, they would require $2^{\lambda}$ basic
computational operations.
\item $KeyGen\left(Params\right)\to\left(sk,pk,ek\right)$: Key generation
(KeyGen) takes as input the encryption parameters and a secret key,
a public key and evaluation key. 

\paragraph{The secret key $sk$ is mainly used for decryption, the public key
$pk$ is used for encryption, and the evaluation key $ek$which is
used to evaluate homomorphic operations on ciphertexts as we shall
see later. Both the $pk$ and the $ek$ can be public.}
\item $Encrypt\left(pk,m\right)\to c$: Encrypt takes as input $pk$ and
a plaintext message $m$ in the plaintext space $P$, and returns
a valid ciphertext $c$ from the ciphertext space $\mathcal{C}$.
\item $Decrypt\left(sk,c\right)\to m$: Decrypt takes as input $sk$ and
a valid ciphertext $c$ in $\mathcal{C}$, which encrypts message
$m$ in $P$, and returns $m$.
\item $EvalAdd\left(params,ek,c_{1},c_{2}\right)\to c$: takes two ciphertexts
and adds their underlying value $m_{1,}m_{2}$ respectively. outputs
the encryption of $m_{1}+m_{2}$

\paragraph{we can even switch $c_{1}$ or $c_{2}$ with a plaintext $m$. the
result would be the encryption of the addition between the plain text
and the underlying encrypted value.}
\item $evalMult$ same thing...
\item more ops$\dots$
\end{itemize}

\section{Plaintext and Ciphertext Spaces}
\begin{defn}
The notation $\Z_{a}\left[x\right]/\left(x^{n}+1\right)$ can be viewed
as the set of polynomials with integer coefficients modulo both a
and $\left(x^{n}+1\right)$, i.e., with coefficients in $\left\{ \lceil-\frac{a}{2}\rceil,\dots\lfloor\frac{a-1}{2}\rfloor\right\} $
(from $-a/2$ to $a/2$ ) and of degree less than $n$. (i've read
another definition, where we can just have coefficients modulo $a$.
\begin{itemize}
\item K{[}x{]} will meanthat $k$ is the field we choose our coefficients
from. and $x$ is the number of variables. 
\end{itemize}
\end{defn}

\begin{example}
The following examples are of valid plaintext messages for the parameters
$n=4$ (degree must be less than that) and $t=5$ (to choose coefficients):
\begin{enumerate}
\item $m_{0}=1+2x+1\cdot x^{2}-1\cdot x^{3}$
\item $m_{2}=-1-2x-1x^{2}+2x^{3}$ 
\end{enumerate}
\end{example}

The plaintext and ciphertext spaces in BFV are defined over two distinct
polynomial rings. the plaintext space is denoted by the polynomial
ring $\mathcal{P}=R_{t}=\Z_{t}\left[x\right]/\left(x^{n}+1\right)$,
that is, polynomials of degree less than $n$ with coefficients modulo
$t$. \\
the ciphertext space is denoted by $\mathcal{C}=\left(\Z_{q}\left[x\right]/\left(x^{n}+1\right)\right)\times\left(\Z_{q}\left[x\right]/\left(x^{n}+1\right)\right)$. 

\section{BFV params}

basically, some random distributions. 
\begin{itemize}
\item $R_{2}$ used to sample polynomials with coefficients in $\left\{ -1,0,1\right\} $.
\item $\mx$ is the error distribution, which is discrete Gaussian distribution.
\item $R_{q}$ is a uniform random distribution over $R_{q}$.
\end{itemize}

\section{Plaintext Encoding and Decoding}

Recall that the plaintext space is the polynomial ring $R_{t}$. This
means that messages need to be converted to polynomials in $R_{t}$.
Let $m$ denote an integer message we would like to encrypt in FHE.
The first encoding scheme (let\textquoteright s call it the naive
encoding scheme) composes the plaintext element (polynomial) as $M=m+0\cdot x+0\cdot x^{2}+\cdot\cdot\cdot+0\cdot x^{n-1}$,
the constant polynomial. this scheme is extremely naive and inefficient.
Let's do better.

\paragraph{another simple solution, but effective, would be to take the message
$m$'s binary representation $a_{0}a_{1}a_{2}\dots$ and convert them
to the coefficients of the polynomial. If we have less bits than coefficients,
set all coefficients with matching bits as $0$. Probably can take
the bytes instead of simple bits too. }

\paragraph{To ensure that the results of homomorphic evaluation matches the
expected results of the computation of interest, we need to ensure
that the degree of the plaintext coefficient does not wrap around
$n$ and the coefficients do not wrap around $t$.}

\section{Key generation}

The secret key $sk$ is generated as a random ternary polynomial from
$R_{2}$, a polynomial of degree $n$ with coefficients in $\left\{ -1,0,1\right\} $.

\paragraph{The public key $pk$ is a pair of polynomials $\left(pk_{1},pk_{2}\right)$
calculated as follows: }

\begin{align*}
pk_{1} & =\left[-1\cdot\left(a\cdot sk+e\right)\right]_{q}\\
pk_{2} & =a
\end{align*}
 Where $a$ is a random ploynomial in $R_{q}$ ($R_{q}=\Z_{q}\left[x\right]/\left(x^{n}+1\right)$).
$e$ is a random error polynomial sampled from $\mx$. the notation
$\left[\cdot\right]_{q}$ means that the polynomial arithemtic should
be done modulo $q$. Note that as $ok_{2}$ is in $R_{q}$, polynomial
arithmetic should also be performed modulo the ring polynomial modulus
$\left(x^{n}+1\right)$.

\section{Encryption and Decryption }

encrypting an encoded message $m$ requires $3$ small random polynomials\"{ }$u\in R_{2}$
and $e_{1},e_{2}\in\mx$. the ciphertext $c=\left(c_{1},c_{2}\right)$
is generated as follows:
\begin{align*}
c_{1} & =\left[pk_{1}\cdot u+e_{1}+\lfloor\frac{q}{t}\rfloor\cdot m\right]q\\
c_{2} & =\left[pk_{2}\cdot u+e_{2}\right]
\end{align*}

Decryption is performed by evaluating the ciphertext on the secret
key as follows and inverting the scaling factor $\left(\lfloor\frac{q}{t}\rfloor\right)$
applied in the encryption:
\[
m=\left[\lceil\frac{t\cdot\left[c_{1}+c_{2}\cdot sk\right]q}{q}\rceil\right]t
\]
 let us expand this to gain better understanding.
\begin{align*}
c_{1}+c_{2}\cdot sk & =pk_{1}\cdot u+e_{1}+\lfloor\frac{q}{t}\rfloor\cdot m+\left(pk_{2}\cdot u+e_{2}\right)\cdot sk=\\
 & =\underbrace{-\left(a\cdot sk+e\right)}_{pk_{1}}\cdot u+e_{1}+\lfloor\frac{q}{t}\rfloor\cdot m+a\cdot u\cdot sk+e_{2}\cdot sk=\\
 & =\cancel{-a\cdot u\cdot sk}-e\cdot u+e_{q}+\lfloor\frac{q}{t}\rfloor\cdot m+\cancel{a\cdot u\cdot sk}+e_{2}\cdot sk=\\
 & =\lfloor\frac{q}{t}\rfloor\cdot m-e\cdot u+e_{1}+e_{2}\cdot sk\\
 & =\lfloor\frac{q}{t}\rfloor\cdot m+\underbrace{e_{1}+e_{2}\cdot sk-e\cdot u}=\lfloor\frac{q}{t}\rfloor\cdot m+v
\end{align*}
 the infinity norm of $v$ (largest abs value from the coefficients)
is pretty small: all of these: $sk,e,e_{1},e_{2}$ are all \textbf{\uline{small}}
polynomials. \.{I}f these polynomials are bounded by some $\beta$
then $\left|\left|v\right|\right|\le2n\cdot\beta^{2}+\beta$. (I'm
skipping the proof of that). \\
They ensure that the noise is small, and thus they can recovering
it.

\section{Doing ops:}

addition is very simple, and the additional error is not high. (can
just add the cipher-texts together). Multiplication adds a lot of
noise, in addition to that, from $2$ cipher-text\.{s} we get $3$
output cipher-texts (polynomials) which means a different encryption
procedure (can be done by using exponents of the secret key). To overcome
this one should do relinearization. 

\section{Maintenance Operations}

The BFV scheme include operations that do not effect the underlying
plaintext, but are needed for implementation reasons:

\paragraph{According to the ``Protecting Privacy through Homomorphic Encryption''
ciphertext-ciphertext multiplication have a side effect of requiring
a different secret--key to decrypt the result than what was needed
before the operation. thus, multiplication is followed by a key switching
opeation to restore the secret key back to the original one. (relinearization).
Avoiding relianirization is possible, but will reduce noise budget
quicker. In addition to that, ops on non-relinearized ciphertexts
are much slower.}

\paragraph{Another such operation is \textbf{bootstrapping}, which ``refreshes''
a ciphertext and reduces the level of noit in it, to support more
computations. It is a very expensive operation, and hence it isn't
often used/ implemented}

\section{security of the scheme}

Choosing optimal BFV parameters that maximize performance and respect
security and functionality constraints is an art that is practiced
by expert cryptographers. but there is a standard one can follow.

But mainly, we first start by choosing the max size of integers $\left(q\right)$
for the coefficients, and the max polynomial degree $\left(n\right)$.
but generally, larger $n$ gives more security (but slower ops), larger
$q$ means we can do more complex computations. 

\paragraph{Ciphertexts in these encryption schemes contain a noise component
(which is important for security), and that noise grows with each
operation (The encrypted result can only be decrypted if the noise
is smaller than $q$, hence using larger values of $q$ imply that
we can do more operations).}

\section{Relinearization}

Remeber we generated another key along with the private and public.
called $ek=\left(ek_{0},ek_{1}\right)$. using this key as randomness
source, we can relinearize the result of multiplication: the new ciphertext
would be :
\begin{align*}
c_{1} & =\left[C_{1}^{*}+ek_{0}\cdot C_{3}^{*}\right]_{q}\\
c_{2} & =\left[C_{2}^{*}+ek_{1}\cdot C_{3}^{*}\right]_{q}
\end{align*}
Remember, decryption is : $c_{1}+c_{2}\cdot sk$. After doing that,
the decryption would result with: 
\[
C_{1}^{*}+C_{2}^{*}\cdot sk+C_{3}^{*}\cdot sk^{2}+C_{3}^{*}\cdot e
\]
 which would decrypt just fine, but with a big error $\left(C_{3}^{*}e\right)$!
We can fix that by using base decomposition.


\section{Base Decomposition}


\chapter{Secret sharing, distributed key generation and threshold cryptography}
\section{Shamir secret sharing}
Given a secret $S$, generate random polynomial 
$p = S + a_0\cdot x + a_1\cdot x+a_2\cdot x^2+\dots$ of degree $f+1$.
create shares $(p(1),p(2),\dots, p(n))$ where $n\ge f+1$ and send it to nodes $(1,2,...n)$.
The nodes will publish their shares when they want to reconstruct the secret.
Using Lagrange interpolation and $f+1$ shares, one can reconstruct the polynomial $p(0)=S$ to learn the secret.

\section{Verifiable secret sharing}
The dealer will generate a random polynomial $P(x)=S+a_1\cdot x +a_2\cdot x^2 +\dots a_n\cdot x^n$. 
It'll broadcast the polynomial as follows: $\{g^{a_i} | i\in [n]\cup {S}\}$.
Then it'll send to each node $i$ its share of the polynomial $P(i)$. 
To verify any share, including shares of other nodes, compute the following: 
$$ g^{P(i)} =
 g^{S}\cdot (g^{a_1})^{i} \cdot (g^{a_2})^{i^2}\cdots  =
 \prod_{j=0}^{k} (g^{a_j})^{i^j} = 
 g^{\sum_{j=0}^{t} a_j \cdot i^j} = 
 g^{P(i)} $$

Every node can compute for any $i$ the value $g^{P(i)}$ using the hidden coefficient broadcasted by the dealer.  
The ability to compute $g^{P(i)}$ guarantees that no one can publish a corrupt share and fool other nodes when they reconstruct the secret.


\section{Distributed key generation}
\subsection{protocol}
Assumptions, $n$ players, where each player has a broadcast channel (Might cost $n^2$ to publish through) and
a private channel to the other players.
Note: I'll use player/ member interchangeably.
\begin{enumerate}
  \item Each member performs VSS.
  That is, player $i$ generates a random polynomial 
  $p_{i}(x)=a_0+a_1\cdot x +a_2\cdot x^2 +\dots a_t\cdot x^t$, and broadcasts $ \{g^{a_i} | i \in [t]\}$.
  Then it sends a private share $ p_{i}(j)$ to each player $j$ where $j>0$.
  \item Each member verifies the share it receives according to the VSS protocol.
  \item Each member $j$ takes the shares it received $\{p_{1}(j),p_{2}(j),\dots\}$ and adds them together. 
  Then publish $ g^{y_i}=g^{\sum_{i}{p_{i}(j)}}$.
  \item Each member verifies these shares. How? They take all the broadcasted values from the first step
  as follows:$ \{g^{a_{ij}} | i \in [t], j \in Players\}$ and compute:
  $$\{\prod_{j}{ g^{a_{1j}}}, \prod_{j}{ g^{a_{2j}}},\dots\}=$$
  $$\{ g^{\sum_{j}{a_{1j}}}, g^{\sum_{j}{a_{2j}}}\} $$ 
  Each member should be able to verify the share their peers sent using these values.
  Denote $\mathcal{Q}$ the distributed polynomial.
  Example:$$g^{\mathcal{Q}(k)}=\prod_{i}(g^{\sum_{j}{a_{ij}}})^{k^i}= g^{\sum_{i}{p_i(k)}}=g^{y_k}$$
\end{enumerate}
\subsection{complexity}
\paragraph{Communication complexity} varies with the costs of broadcasting. using reliable broadcast means
Each of these broadcasts costs $O(n^2)$. with up to constant rounds of broadcasting,
 we get $O(n^3)$ total communication costs in the system. 
 Without reliable broadcast - $O(n^2)$ communication costs
 \paragraph{Computation complexity.} The top computation cost is creating $\mathcal{Q}$ then verifying each value.
 That is, computing $ \{ g^{\sum_{j}{a_{1j}}}, g^{\sum_{j}{a_{2j}}},\dots\} $  is $O(n^2)$, and computing it for each player: $O(n^3)$ 


\section{Largange interpolation in the exponent} %https://crypto.stackexchange.com/questions/67500/how-to-apply-lagrange-interpolation-on-bilinear-pairings
We can modify cryptographic schemes using Lagrange interpolation to work with $f<n$ participants.

Given a dataset of coordinate pairs $(x_j,y_j)$ on 
a polynomial $P(X)=\sum_{i=0}^{k}{a_i^{i}\cdot x^k}$ we can interpolate it as follows:
 $$P(X)=L(x)=\sum _{j=0}^{k}y_{j}\ell _{j}(x)$$
 where $\ell _{j}(x)$ is:

 $$\prod_{0\leq m\leq k, \ m\neq j}\frac {x-x_{m}}{x_{j}-x_{m}}$$
That is, we ensure $L(x_j)=y_j$.

\subsection{Using it in crypto}
For our convinicece, we publish onlt shares of the form: $\{(i,P(i))| i > 0\}$.

Denote: $i_j\in T\subseteq [n]$,  means index of player $j$.
in order to reconstruct we'll need enough indices such that $|T|=deg(P)+1$.

So to evaluate $L(0)$ we'll need to compute for each $i_j\in T$:
$$
 \ell_{i_j}(0) = \frac{
 \prod _{k\in T \setminus \{i_j\}}{\textbf{0}-k}
}{
  \prod_{k\in T \setminus \{i_j\}}{ (i_j - k)}
}
$$
Now, let us finally evaluate the secret:
$$ L(0) = \sum_{i_j \in T} {\ell_{i_j}\cdot P(i_j)} $$


\subsubsection*{$n-out-of-n$ protocol}
We'll take a complex and unfamiliar example to ensure one can apply it to other schemes.
NOTE: We rely in the following example on pairing-based cryptography. 
It'll have slight differences. 
for example, using the key pair $(sk, g^{sk})$ one can sign a message $m$ as follows: $H(m)^{sk}$.

Let's begin:


A node can publish a secret tied to a specific ID in the following protocol (Assume we have pairings).
Each user has a key pair $(sk_{i}, pk_{i})$, 
and the shared public key would be $\prod_{i}pk_{i}=pk$.
that is $\prod_{i}g^{sk_{i}}=g^{\sum_{i}sk_{i}}$.


to hide a new transaction $tx$: sample new keys: 
$\left(sk',pk'\right)$ and a random number $r$.
\begin{itemize}
\item compute $\gamma=Enc_{pk'}\left(tx\right)$
\item compute $c=\left(\underbrace{g^{r}}_{c_{L}},\underbrace{e\left(pk,H\left(\gamma\right)^{r}\right)\cdot sk'}_{c_{R}}\right)$ 
\item send $\left(c,\gamma,pk'\right)$.
\end{itemize}


Now, when every server signs: $\sigma_{i}=H\left(\gamma\right)^{sk_{i}}$\\
we can compute the product signature: $\sigma=\prod H\left(\gamma\right)^{sk_{i}}$
which can be used to decrypt the temp secret key: 
\begin{align*}
 & \frac{c_{R}}{e\left(c_{L},\sigma\right)}=\frac{e\left(g^{x},H\left(\gamma\right)^{r}\right)sk'}{e\left(g^{r},\sigma\right)}=\\
 & =\frac{e\left(g^{\sum sk_{i}},H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g^{r},H\left(\gamma\right)^{\sum sk_{i}}\right)}=\\
 & =\frac{e\left(g^{\sum sk_{i}},H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g,H\left(\gamma\right)\right)^{r\cdot\sum sk_{i}}}=\\
 & =\frac{e\left(g,H\left(\gamma\right)\right)^{r\sum sk_{i}}\cdot sk'}{e\left(g,H\left(\gamma\right)\right)^{r\cdot\sum sk_{i}}}=\\
 & =sk'
\end{align*}
 we managed to find out the temp secret key. now we can get the value
under $\gamma=Enc_{pk'}\left(tx\right)$.


\subsubsection*{$f-out-of-n$ protocol}
We assume all nodes have shares of the same polynomial $P$.
This protocol will have slight changes from the one described before.
It'll ensure we need only $f-out-of-n$ signatures to reconstruct the secret.


Each player holds a share $s_j$ (and a matching public key $g^{s_j}$), generated from Polynomial $P$. 
The shared secret key is $P(0)= S = \sum_{k \in T}{\ell_k(0)\cdot s_k}$,
and the public key is 
$$
  PK=
  \prod_{k\in T}{(g^{s_k})^{\ell_k(0)}} =
  g^{\sum_{k\in T}{\ell_k(0)\cdot s_k}} =
  g^{L(0)}=g^{P(0)}=g^S 
$$
for $|T|=f+1$ indices.

\paragraph*{Creating new secret}
For each transaction $tx$: sample new keys: $\left(sk'\right)$ and a random number $r$.
\begin{itemize}
\item compute $\gamma=Enc_{sk'}\left(tx\right)$
\item compute $c=\left(\underbrace{g^{r}}_{c_{L}},\underbrace{e\left(PK, H\left(\gamma\right)^{r}\right)\cdot sk'}_{c_{R}}\right)$ 
\item send $\left(c, \gamma\right)$.
\end{itemize}



\paragraph*{reconstruction}


With $f+1$ signatures over $H(\gamma)$, we can recompute the secret and extract out of $c$ the decryption key $sk'$.
When a player receives a signature $\sigma_{i}=H\left(\gamma\right)^{s_{i}}$
It verifies the signature and then stores $ (\sigma_i)^{\ell_i(0)}$.
With enough signatures, we can compute the product signature: $$
\sigma=\prod_{k\in T}{\sigma_k^{\ell_k(0)}} = 
\prod_{k\in T}{H\left(\gamma\right)^{\ell_k(0)\cdot s_{k}}} = 
H\left(\gamma\right)^{\sum_{k\in T}{\ell_k(0)\cdot s_{k}}}=
H\left(\gamma\right)^{L(0)} =
H\left(\gamma\right)^{S}
$$
Which can be used to decrypt the temp secret key: 
\begin{align*}
 & \frac{c_{R}}{e\left(c_{L},\sigma\right)}=\frac{e\left(PK, H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g^{r},\sigma\right)}=\\
 & =\frac{e\left(g^S, H\left(\gamma\right)^{r}\right)\cdot sk'}{e\left(g^{r},H(\gamma)^S\right)}=\\
 & =\frac{e\left(g^S, H\left(\gamma\right)^{r}\right)}{e\left(g^{r},H(\gamma)^S\right)} \cdot sk'=\\
 & =\frac{e\left(g, H\left(\gamma\right)\right)^{S\cdot r}}{e\left(g,H(\gamma)\right)^{r\cdot S}} \cdot sk'=\\
 & =sk'
\end{align*}
 we managed to find out the temp secret key. now we can get the value
under $\gamma=Enc_{pk'}\left(tx\right)$. as wanted.

\chapter{protocols for identification and login}
\section{Identification Protocols}.

\subsection{Types of adversaries}

The identification protocol is a set of a prover $P$ and a verifier
$V$. where the prover wants to gain access to some resource, and
to do so, the verifier must give it access. the verifier will only
give access to a prover that convinces it that it has the rights to
that resource. for example, $P$ wants to enter its house, and to
do so it must unlock the door. the convincing method is a key.
\begin{description}
\item [{Direct$\,\,$attacks}] The adversary is not able to eavesdrop.
Then using no information other than what is publicly avail- able,
the adversary must somehow impersonate the prover to the verifier.
A simple password protocol is sufficient to defend against such direct
attacks.
\item [{Eavesdropping$\:$attacks}] The adversary can eavesdrop and obtain
the transcript of several interactions between the prover and verifier.
In this case the simple password protocol is insecure. However, a
slightly more sophisticated protocol based on one-time passwords (TBD)
is secure.
\item [{Active$\:$attacks}] an active adversary that interacts with the
prover. The adversary uses the interaction to try and learn something
that will let it later impersonate the prover to the verifier. Identification
protocols secure against such active attacks require interaction between
the prover and verifier. They use a technique called challenge-response.
\end{description}

\subsection{Salting}

\paragraph{Storing the password in plaintext is prone to active attacks, once
the verifier is compromised, the adversary can gain access easily.
A simple solution would be to hash the plain-texts. unfortunately
the space of possible passwords being used is not very large. Hence
in addition to hashing the plain-texts, add salt! }

\paragraph{To salt a plain-text, the verifier should add some random string
to it, then store the salt as plain-text, and hash the password and
the salt concat to it ($salt,Hash\left(salt||password\right)$).}

\paragraph{Salting ensures a direct attack would need to run an exhaustive search
over $D\times S$ where $D$ is the dictionary with all weak passwords
and $S$ is the space of random strings the verifier uses, for example
salt size can be $|S|=2^{128}$. }

\paragraph{That is not really the case though, it just ensures the attacker
cannot use a preprocessing algorithm to have efficient attacks. (?the
attacker needs to make a preprocess for all salts it saw in the server
along with the dictionary.) \protect \\
Now its best case would be to run on a dict along hash the plaintext
hash with the word from the dict in the hopes of finding a similar
hash in the servers password file.}

\subsubsection{salt and pepper}

skipped it

\subsection{eavesdrop safe}

\subsubsection{Hotp}

HOTP is a protocol for identification which is safe against eavesdrop
attacks. 

\paragraph{This attack attempts to change the password after each use. To do
so, the prover and verifier should share a secret, which they will
then be used to generate some proof of authenticity. Using $HMAC$
(or a $PRF$ as follows $F\left(k,i\right)$) the prover generates
a new value over a shared counter: $Hmac\left(i\right)$ and will
send it to the verifier. verifier can authenticate it. and then they
both advance $i$ by $1$. }
\begin{rem}
We can improve it by sending both $i$ and the output of the $HMAC$
over $i$, this way the verifier can check if $i$ is greater than
its counter $i'$, so they do not have to be matching counters at
all times.
\end{rem}

\begin{rem}
This verification protocol changes state only upon an attempt to login.
A user that does not login frequently, might be compromised if an
attacker gained the latest token. The attacker can sell the obtain
token to anyone which should give access once unless the user logins
again. 
\end{rem}


\subsubsection{TOPT: time base OTP }

Instead of a counter, one can use the current time, and each login
attempt is only valid if the timestamp is recent enough, say 10 seconds.

\subsubsection{S/key }

TODO.

attempts to solve the leaking key issue: \\
generate random $k$, give the verifier $H^{(n+1)}(k)$. the prover
stores $(k,n)$ to send identification request: 
\begin{itemize}
\item $P$ sends $t=H^{i}(k)$ then sets $i=i-1$. 
\item $V$ will inspect that $H(t)$ equals to what it stored, if it does
it updates the storage as $t$.
\end{itemize}
this can be used for $n$ times, afterwards needs to be regenerated.
kinda cool. 

basically, the provers sends $H^{n}(k)$ then $H^{n-1}\left(k\right)$
... $H(k)$.
\begin{itemize}
\item Assumes that the key is kept secret by the client
\item the resulting password is at least 128bit, which is long to type by
humans. 
\end{itemize}
%
You reached 18.6 in the book, which is talking about security against
active attacks. 

\section{Active attack}

the attacker can impersonate the verifier for a brief moment, and
its goal is to find a secret to fool the actual verifier. 

thus HOTP is easy to break, gain a legit one time password and forward
it to the verification protocol. 

\subsection{challenge-response protocol: }

the verifier sends a random challenge $c$, the prover uses a mac
over the challenge $c$ and send it back. the attacker can only interact
with the prover, it cannot prepare ask the prover all possible challenges
the verifier will chuck at him. and because we use $MAC$ the attacker
cannot forge a response from the prover. 

\subsubsection{improvement }

to ensure the verifier can be compromised and the attacker can't do
anything to gain access later using active attack - we use signature
scheme instead of mac. 

\chapter{Identification and signatures from sigma protocols}

This chapter will be useful to develop zero--knowledge proofs.

\section{Schnorr\textquoteright s identification protocol }

\paragraph{Schnorr's identification protocol is a basic block for building signature
schemes with DH assumption as its base.}

This will be our first proof of knowledge ever to be seen.

\paragraph{This protocol can be proved secure against eavesdropping attacks,
assuming the discrete logarithm problem is hard.}

Let $\G$ be a cyclic group of prime order $q$with a generator $g\in\G$.
Suppose the prover has a secret key $\alpha\in\Z_{q}$ and a corresponding
public key $u=g^{\alpha}$. $P$ wishes to prove to an identifier
$V$ that it knows $\alpha$.

\subsubsection{protocol}

both the prover and the verifier generates random numbers respectively
$k,c$. The prover send $g^{k}$ and once it receives the challenge
$c$ from the verifier, it'll need to compute $t=k+\alpha\cdot c$
and send $t$ to the verifier. in turn, the verifier should compute
the following:$\left(u\right)^{c}\cdot g^{k}=g^{k+\alpha\cdot c}$
which should be equal to $g^{t}$.

\paragraph{A keen eye could see that this is very similar already to Schnorr's
signature scheme.}

\subsubsection{Honest verifier zero knowledge and security against eavesdropping}

We prover that the protocol is eavesdrop safe by assuming the adversary
has access to $vk$, and that it had seen a conversation between $P$
and $V$. The idea is to show that these conversations do not help
the adversary, because the adversary could have efficiently generated
these conversations by himself, given $vk$ (but not $sk$).
\begin{defn}
Let $\mathcal{I}=(G,P,V)$ be an identification protocol. We say that
$\mathcal{I}$ is honest verifier zero knowledge, or $HVZK$ for short,
if there exists an efficient probabilistic algorithm $Sim$ (called
a simulator) such that for all possible outputs $(vk,sk)$ of $G$,
the output distribution of $Sim$ on input $vk$ is identical to the
distribution of a transcript of a conversation between $P$ (on input
$sk$) and V (on input $vk$).
\end{defn}


\paragraph{Comments on the terminology are in order. The term \textquotedblleft zero
knowledge\textquotedblright{} is meant to suggest that an adversary
learns nothing from $P$, because an adversary can simulate conversations
on his own (using the algorithm $Sim$), without knowing $sk$. The
term \textquotedblleft honest verifier\textquotedblright{} conveys
the fact this simulation only works for conversations between $P$
and the actual, \textquotedblleft honest\textquotedblright{} verifier
$V$ , and not some arbitrary, \textquotedblleft dishonest\textquotedblright{}
verifier, such as may arise in an \textbf{active attack} on the identification.}
\begin{thm}
If an identification protocol $\mathcal{I}$ is secure against direct
attacks, and is HVZK, then it is secure against eavesdropping attacks. 
\end{thm}
The main idea here: if I'm secure against someone interacting maliciously with the verifier.
and in addition to that, my regular protocol does not provide any useful information someone
can use later on: im safe against eavsedrop attacks too.

Schnorr's protocol is HVZK, they prove it using a simulator.
In addition to that, they show it's safe against direct attacks by showing that 
if there was some attacker that can break it, it can generate twice accepting answers
to the verifier.
then they can use these two answers to BREAK the discrete log assumption.


\subsection{ECDSA }

The ECDSA signature scheme $(G,S,V)$ uses the group of points $\G$
of an elliptic curve over a finite field $F_{p}$. Let $g$ be a generator
of $\G$ and let $q$ be the order of the group $\G$, which we assume
is prime. Im skipping the algorithm, because it isn't as elegant.
in addition to that, Schnorr sigs are strongly secure, but ECDSA are
not. Given an ECDSA signature $\sigma=\left(r,s\right)$ on a message
$m$, anyone can generate more signatures on $m$.


\section{Sigma protocols: basic definitions }

Schnorr\textquoteright s identification protocol is a special case
of an incredibly useful class of protocols called Sigma protocols.
We'll soon see the basic concepts associated with Sigma protocols
and how they can become helpful to us.\\
Later we'll see how Sigma protocols are useful to us, even out of
the context of identification and signatures.
\begin{defn}
(Effective relation). An effective relation is a binary relation $R\subseteq X\times Y$,
where $X,Y$ and $R$ are efficiently recognizable finite sets. Elements
of $Y$ are called \textbf{statements}. If $\left(x,y\right)\in R$,
then $x$ is called a witness for $y$.
\end{defn}

\begin{defn}
Sigma Protocol. Let $R\subseteq X\times Y$ be an effective relation.
A \textbf{Sigma Protocol }for $R$ is a pair $\left(P,V\right)$.
\begin{itemize}
\item $P$ is an interactive protocol algorithm called the \textbf{prover},
which takes as input a witness--statement pair $\left(x,y\right)\in R$.
\item $V$ is an interactive protocol algorithm called the \textbf{verifier},
which takes as input a statement $y\in Y$, and which outputs accept
or reject.
\item $P$ and $V$ are structured so that an interaction between them always
works as follows:
\begin{itemize}
\item To start the protocol, $P$ computes a message $t$, called the commitment,
and sends $t$ to $V$;
\item Upon receiving $P$\textquoteright s commitment $t$, $V$ chooses
a challenge $c$ at random from a finite challenge space $C$, and
sends $c$ to $P$;
\item Upon receiving $V$ \textquoteright s challenge $c$, $P$ computes
a response $z$, and sends $z$ to $V$;
\item Upon receiving $P$\textquoteright s response $z$, $V$ outputs either
\textbf{accept} or \textbf{reject}, which must be computed strictly
as a function of the statement $y$ and the conversation $\left(t,c,z\right)$.
In particular, $V$ does not make any random choices other than the
selection of the challenge --- all other computations are completely
deterministic.
\end{itemize}
\end{itemize}
We require that for all $\left(x,y\right)\in R$, when $P\left(x,y\right)$
and $V\left(y\right)$ interact with each other, $V\left(y\right)$
always outputs accept.
\end{defn}

\begin{rem}
So a sigma protocol, is any prover verifier challenge where the prover
knows some witness to y and want to prove that $y$ is in the language
to the verifier?
\end{rem}

If the output is accept we call the conversation $\left(t,c,z\right)$
an accepting conversation for $y$.
\begin{example}
It should be clear that for Schnorr\textquoteright s identification
protocol $\left(G,P,V\right)$, the pair $\left(P,V\right)$ is an
example of a \textbf{Sigma protocol} for the relation $R\subseteq X\times Y$,
where
\[
X=\Z_{q},Y=\G\text{ and }R=\left\{ \left(\alpha,g^{\alpha}\right)\in\Z\times\G\right\} .
\]

TODO continue
\end{example}


\chapter{MPC}
We have a function f that takes n inputs and produces m outputs:
$$  (y_1,...,y_m) = f(x_1,...,x_n).$$
We also have N parties, $P_1,...,P_N$. 
Their goal is to run a protocol where each input value $x_i$ is 
contributed by one of the parties and each output $y_j$ is obtained by one or more of
 the parties.


We want to design an efficient protocol for this problem that provides
\emph{ privacy, soundness, and input independence}.

\section{Wanted properties}
\begin{itemize}
  \item Privacy: No part learns anything about any other part's inputs
  (except for the information that is inherently revealed by the outputs).
  \item Soundness/correctness: honest parties compute correct outputs. 
  \item Input independence: All parties must choose their 
  inputs independently of the other parties' inputs 
  (No one can use Alice's inputs to their advantage).
  \item Guaranteed output delivery: all honest parties are guaranteed to obtain
  their output.
  \item Fairness: If any party (including corrupted members) obtains their output, 
  then all honest parties do so.
\end{itemize}
\section{Formal Security}
The way to define security formally is to say that an attack on the protocol in 
the "real world" 
is equivalent to some attack on the protocol in an "ideal world" in which 
no damage can be done.

In the ideal world, the protocol is implemented using a trusted 
party to which all parties (both honest and corrupt) submit inputs, 
and from which all parties (both honest and corrupt) obtain their designated outputs. 
The trusted party itself cannot be corrupted.

We then describe the details of the ideal-world execution, including the 
behavior of the trusted party who evaluates the function.

The definition of security then basically says: for every efficient adversary $A$ 
in the real world, there exists an "equivalent" efficient 
adversary $\mathcal{S}$ in the ideal world (usually called a simulator).
Since there is no possible attack in the ideal world, 
there is no possible attack in the real world.

the informal notions of \emph{privacy, soundness, and input independence} are
 implied by this type of definition.

 Essentially we'll want to show that the ideal world we describe is 
 "equivalent" to the real world.

 \subsection{A few applications of MPC}
 \begin{itemize}
  \item Elections: Without MPC, parties submit votes to a trusted server $T$ who 
  counts the votes and states the winner.
  \item Privacy-preserving mining of medical data. Two hospitals want to share data,
  to perform research, but cannot share it due to regulations.

 \end{itemize}

\section{Securely evaluating arithmetic circuits}

\input{computer-sceince/algorithms.tex}