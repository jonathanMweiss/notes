\chapter{Lattices}
The following chapters are chosen parts from Peikert's Survey, and the notes from the MIT course Advanced Topics in Cryptography: From Lattices to Program Obfuscation.

\section{Basic definition}

Latices are n-dimensional subsets of $\mathbb{R}^n$. 
A lattice $\mathcal{L}$ is both 
\begin{itemize}
    \item an \emph{addative} subgroup: $0\in \mathcal{L}$, and for every $x,y\in \mathcal{L}$ so are $-x, x+y\in \mathcal{L}$.
    \item \emph{discrete}: every $x\in \mathbb{L}$ has a ball/ neighbourhood in $\mathbb{R}^n$, where $x$ is the only lattice point. 
\end{itemize}

for instance $\mathbb{Z}^n$ is a lattice, or just the even numbers is a lattice. In addition, given a lattice $\mathcal{L}$, for any $c\in \mathbb{R}$, $c\cdot\mathcal{L}$ is also a lattice.

Every lattice has a base (since it is a vector space).

Every lattice has a dual: $\mathcal{L}^*=\{w : <w,\mathcal{L}>\subseteq \mathbb{Z}\}$


\begin{definition}
    The minimum distance of a lattice $\mathcal{L}$ is the length of a shortest nonzero lattice vector:
    $$ 
    \lambda_1(\mathcal{L}) := \min_{v\in \mathcal{L} \setminus \{0\}}{||v||} 
    $$
\end{definition}
\subsection{Problems Over Lattices}
Apperently it is not easy to solve things over lattices. 

\begin{definition}[Shortest Vector Problem (SVP)]
    Given an arbitrary basis $B$ of some lattice $mathcal{L}= mathcal{L}(B)$ ($mathcal{L}$ is defined via the basis $B$),
find a shortest nonzero lattice vector, i.e., a $v \in mathcal{L}$ for which $||v|| = \lambda_1(\mathcal{L})$.
\end{definition}
Think about this one, like given a random basis of lattice vectors. It is hard to find all the vectors around the origin. 
Treat it like other problems that once they are discrete become hard (linear programming for instance).


There are many other problems, but i won't write about them.

\subsection{(Discrete) Gaussians and Subgaussians}
Discrete gaussian samples for  lattice are a cornerstone in many of 
lattice-based cryptographic primitives. But i won't write about it just yet.
treat it like a black box.



\section{Modern Foundations}
In this chapter we survey the main foundational works that directly underlie most modern lattice-based
cryptographic schemes. These include the two main average-case problems SIS and LWE, their analogues
over rings, and analytical techniques involving (discrete) Gaussian probability distributions
\subsection{Short Integer Solution (SIS)}
The short integer solution (SIS) problem was first introduced in the seminal work of Ajtai,and has
served as the foundation for one-way and collision-resistant hash functions, identification schemes, digital
signatures, and other "minicrypt" primitives (but not public-key encryption).

Here we define the SIS problem,
survey its connection to worst-case lattice problems, and explore some of its basic properties and immediate
cryptographic implications. (Further applications are described in~\cite[Chapters 5 and 6]{latticebook})


\begin{definition} [Short Integer Solution (${SIS}_{n,q,\beta,m}$)]
    Given $m$ uniformly random vectors $a_i\in \mathbb{Z}_q^n$ form-
ing the columns of a matrix $A\in \mathbb{Z}_q^{n\times m}$, find \emph{nonzero}
integer vector $z\in \mathbb{Z}^m$ of norm $||z|| \le \beta$ such that

$f_A(z):=Az=\sum_{i}{a_i \cdot z_i}=0\in \mathbb{Z}_q^n$
\end{definition}


We now highlight several simple but useful observations about the SIS problem:
\begin{itemize}
    \item without the norm constraints over $z$it is easy to find a solution via Gaussian elimination. Similarly, we
must take $\beta < q$, otherwise $z=(q,0,0,0,0,0...)\in \mathbb{Z}^m$ would be a legitimate (but trivial) solution.
\item any solution for $A$ can easily be extended to $A|A'$, by attaching zeros to $z$ (the norm remains the same). In other
words, we can ignore columns $a_i$ as desired, so the SIS problem can only become easier as $m$ increases. Similarly, it can only become harder as $n$ increases.
\item The norm should be large enough to guarantee a solution, which happens when $\beta  \ge \sqrt{\bar{m}}$ for $m\ge\bar{m}$ the smallest integer greater than $n\log q$. Why? Chris explains in chapter 4.
\item Additional point stating it is collision resistant.
\end{itemize}


\emph{SIS} is NP-Total. it has a solution, and easy to verify but hard to find a solution.
% TODO: fix following
% \subsection{Learning With Errors}
% A very important work of Regev \todo{cite! On lattices, learning with errors, random linear codes} from 2005 introduced the average-case learning with errors (LWE)
% problem, which is the “encryption-enabling” analogue of the SIS problem.

% The two problems are
% syntactically very similar, and can meaningfully be seen as duals of each other

%
%
% CHAPTER
%
%
\chapter{Fully Homomorphic Encryption}
Homomorphic encryption (\emph{HE}) is a form of encryption that allows 
computations to be performed on encrypted data without first having to decrypt it.
More formally:
\begin{definition}[HE]
 Let there be an encryption scheme $\pi = (KeyGen,Enc, Dec)$
 We say that $\pi$ is an homomorphic encryption scheme if
 given $f:\text{PTX-SPACE}\to \text{PTX-SPACE}$ then there
 exists $F:\text{CTX-SPACE} \to \text{CTX-SPACE}$ such that
 given two encrypted messages $c_1=Enc(m_1)$ $c_2=Enc(m_2)$ the following
 applies
   $Dec(F(c_1,c_2))=f(m_1,m_2)$
\end{definition}

That is, we can compute some wanted function $f$.

We have multiple encryption schemes. Some are \emph{partially HE},
like ElGamal, where only multiplication is possible.
\begin{theorem}
 We call the encryption scheme $\pi$ \emph{fully homomorphic encryption} (FHE) if it 
 can support addition, negation and multiplication.
\end{theorem}

As of the year 2024, most of the FHEs are heavy and slow,
or called leveled-FHE, where one must first define their parameters, 
and then it has a limited amount of operations to perform (many additions and a 
handful of multiplications.)

In the following sections, I'll talk about a specific scheme called BGV \cite{BGV},
this is a (leveled)-FHE scheme, which is easy to work with, and relatively efficient.

\section{Usages}
\red{TODO: describe PIR, private machine learning (for finance and medicals), 
private set intersection see 
\href{https://bit-ml.github.io/blog/post/bgv-fully-homomorphic-encryption-scheme-in-python/}{bgv repo}}
\subsection{Hardness}
Unlike older schemes, modern HE schemes don't rely on DDH~\ref{DDH} 
but have a different \emph{hardness} assumption.
So, before we discuss BGV, we must introduce its hardness assumption,
called Ring Learning With Errors (RLWE). 
I will define the RLWE "decision" problem, since by using decisional-RLWE,
it is relatively easier to define encryption schemes under this notion of hardness.
Do note that there is an additional hardness assumption, called "search", 
which is equivalent under specific conditions and parameters to 
the "decisional-RLWE" problem.

For a full, and accurate definition see~\cite[def 3.3]{RLWE}.
\begin{definition} (toy decisional-RLWE)
    Let 
    \begin{enumerate}
        \item $a_i(x)$ be a set of random but known polynomials from $Z_q/\Phi(X)$ with 
        coefficients from $Z_q$.
        \item  $e_i(x)$ be a set of small random and unknown polynomials 
        relative to a bound $B$ in the ring $Z_q/\Phi(X)$.
        \item $s(X)$ be a small unknown polynomial 
        relative to a bound $B$ in the ring $Z_q/\Phi(X)$.
        \item $b_i(x)=a_i(x)\cdot s(x) + e_i(x)$
    \end{enumerate}
    
    Given a list of polynomial pairs $(a_i(x),b_i(x)$) it is computationally infeasible 
    to determine $s(x)$.
\end{definition}

\section{The BGV Encryption Scheme}

While there are more encryption schemes than BGV (for instance BFV which is very similar,
 CKKS for floating point numbers and TFHE which I haven't encountered at all),
I have most of my experience with BGV, and it is very nice scheme, 
where addition and multiplication associativity commutativity and more desired attributes 
hold.  Thus, we will focus on it.


BGV relies on the following parameters
\begin{itemize}
    \item $n$ (a power of 2), the degree of $X^n+1$.
    \item $q$ the ciphertext modulus.
    \item $t$ the plaintext modulus
    \item $\mathcal{X}$ the noise distribution, a discrete Gaussian.
\end{itemize}

In BGV we work with polynomials over $R_q=Z_q/(X^n+1)$.
This ring has polynomials with degree at most $n$ and integer coefficients in $(-q/2,q/2]$.

\begin{remark}
    It is important to understand the relationship between parameters, and choosing parameters 
    is not an easy task, and should not be tampered with lightly.
    There are some parameter generators online to find the best parameters
     for your cause see \href{https://github.com/Crypto-TII/fhegen}{fhegen}.
    
    Some things to consider are $n$, which affects the number of multiplications we can have,
    $q$ which, determines the safety of our scheme, and $t$ which determines 
    the size and efficiency of message packing into our plaintexts. 
    \emph{When $q$ reduces in size, it means better security}.    

    Notice that, smaller $q$ and smaller $n$ mean faster computations.
\end{remark}


\begin{remark}
    \begin{itemize}
        \item \red{check: I think we can treat coefficients as they were in $(0,q]$.}
        \item All polynomial operations are considered $\mod q$
         unless otherwise specified, to ease notation.
         \item When we talk about "small" polynomials, 
         we intuitively think about them as having small coefficients.
    \end{itemize}
\end{remark}

\subsection{Plaintext and Ciphertext Spaces}
The plaintext and ciphertext spaces in BGV are defined over two distinct
polynomial rings. the plaintext space is denoted by the polynomial
ring $\mathcal{P}=R_{t}= Z_{t}\left[x\right]/\left(x^{n}+1\right)$,
that is, polynomials of degree less than $n$ with coefficients modulo
$t$. 
\begin{remark}
    Since Plaintexts must be polynomials in $R_q$, treat 
    $m$ as a string and encode each letter of the string as a coefficient of a polynomial
    $a_{0}a_{1}a_{2}\dots$
\end{remark}


the ciphertext space: $\mathcal{C}=R_q \times R_q$. 

\subsection{Algorithms}
In the following algorithms, $params$ is essentially the chosen security parameters. 
\paragraph{$sk,pk \leftarrow KeyGen(params)$}
The secret key $sk$ should be sampled from a distribution that outputs "small" elements 
with overwhelming probability. In practice (e.g., in Microsoft's SEAL library) $sk\in\{-1,0,1\}^n$,
with the probability of sampling 0 specified as a parameter, and the probability of sampling $-1$ or $1$
being equal. 

Once the secret key is derived, we can compute the public key $pk=(pk_0,pk_1)$.
First, draw a random polynomial $a\overset{r}{\leftarrow} R_q$ and 
noise (vector) $e\overset{r}{\leftarrow} \mathcal{X}$. Then compute 
$pk=(pk_0,pk_1)=(a\cdot sk+t\cdot e, -a)$.

Notice that here we rely on the hardness assumption? 
Can you guess why we multiply the noise by $t$?

\paragraph{$(c_0,c_1) \leftarrow encrypt(m,pk, params)$}
To encrypt we draw noise $e_0,e_1 \overset{r}{\leftarrow} \mathcal{X}$, and a "small" polynomial 
$u\in \{-1,0,1\}^n$ (like the secret key).
Then we compute the ciphertext as follows $$c=(c_0,c_1)= (pk_0\cdot u +t\cdot e_0+m, pk_1\cdot u +t\cdot e_1)$$

(Every element in the ciphertext tuple is in $R_q$).


\paragraph{$m \leftarrow decrypt(c,sk,params)$}

Decryption is performed by evaluating the ciphertext on the secret
key as follows $ m=((c_0+c1\cdot sk) \mod q) \mod t$

The following expansion of the expression above should make it clearer
\begin{align*}
c_{0}+c_{1}\cdot sk & =pk_{0}\cdot u+e_{0}\cdot t+m+(pk_{1}\cdot u+e_{1}\cdot t)\cdot sk=\\
 & =\underbrace{(a\cdot sk +e\cdot t)}_{pk_0} \cdot u + e_{0}\cdot t + m + (\underbrace{-a}_{pk_1}\cdot u+e_{1}\cdot t)\cdot sk=\\
 & = \cancel{a\cdot sk\cdot u} +e\cdot t\cdot u +e_{0}\cdot t + m  \cancel{-a\cdot u\cdot sk} +e_{1}\cdot t\cdot sk = \\
 & = e\cdot t\cdot u +e_{0}\cdot t + m  +e_{1}\cdot t\cdot sk = \\
 & = \underbrace{t\cdot (e\cdot u + e_0 +e_1\cdot sk)}_{error} + m
\end{align*}
If the error is small enough (doesn't cause $m$ to wrap around the modulus $q$), we should be able to eliminate the noise 
by applying $\mod t$ on the result above (e.g., remember that for every number $z$: $z\cdot t \equiv 0 \mod t$).

The decryption won't be correct when we have too much noise since $m$ parts of $m$
will be zeroed out by the $\mod q$ operation we perform.

\paragraph{addition and multiplication}
is simple, we treat the ciphertext tuples and the plaintexts as polynomials in a higher dimension,
that is $R_q[Y]$. The plaintexts are simply constant polynomials, and the freshly encrypted ciphertexts are polynomials 
of degree $1$.
It is a bit hard to see it in this manner, so let us discuss regular polynomials for instance.

Given $a(x)=a_0+a_1x$, $b(x)=b_0$, and $c(x)=c_0+c_1x$ adding them together or multiplying them is simple, right?
\begin{itemize}
    \item $a(x)+b(x)= (a_0+b_0)+a_1x$
    \item $a(x)\cdot b(x)= a_0\cdot b_0 + a_1\cdot b_0 x$
    \item $a(x) \cdot c(x)= (a_0\cdot c_0) +(a_0\cdot c_1 + a_1\cdot c_0)\cdot x + a_1\cdot c_1 \cdot x$
\end{itemize}

Okay, that's easy, right? Well, now you know how to perform addition and multiplication with plaintexts and ciphertexts!
$b(x)$ is a plaintext (since it has only one coefficient $b_0$), $a(x),c(x)$ are ciphertexts
since they are tuples.

In our ciphertext notions:
$p*c=(p\cdot c_0, p\cdot c_1)$,
$c*c'=(c_0\cdot c_0', c_0\cdot c_1' + c_1\cdot c_0', c_1\cdot c_1')$ and you can complete addition by yourself.

\subsection{Advanced Algorithms}
\paragraph{relianization}
The issue with multiplications is that they increase the noise very fast, and it means we'll need to work harder 
for decryption. That is, we increase the "degree" of our ciphertext every time we multiply it
Either we decrypt like so: $decrypt(c, sk, params)= c_0 +c_1\cdot sk+c_2\cdot sk^2+\dots$, 
or we perform relinearization.

I will not describe relinearization here but know that it can be performed between each multiplication
using something called an evaluation key (which is also public). After using the relianization algorithm 
a ciphertext of degree $3$ (i.e., $c\cdot c'$ is of degree $3$) for instance, will return to degree $2$.

\paragraph{key switch}
\red {TODO}
\paragraph{modulus switch}
is used to decrease the noise/error. once can "hop" to decreasing modulus values to reduce the noise, and thus allow 
more multiplications. \red{TODO}.

\paragraph{rotations}
\red{TODO}
\subsection{bootstrapping}
Read \href{https://www.zama.ai/post/what-is-bootstrapping-homomorphic-encryption}{bootstrapping for dummies} by Nigel Smart.

% \section{security of the scheme}

% Choosing optimal BFV parameters that maximize performance and respect
% security and functionality constraints is an art that is practiced
% by expert cryptographers. but there is a standard one can follow.

% But mainly, we first start by choosing the max size of integers $\left(q\right)$
% for the coefficients, and the max polynomial degree $\left(n\right)$.
% but generally, larger $n$ gives more security (but slower ops), larger
% $q$ means we can do more complex computations. 

% \paragraph{Ciphertexts in these encryption schemes contain a noise component
% (which is important for security), and that noise grows with each
% operation (The encrypted result can only be decrypted if the noise
% is smaller than $q$, hence using larger values of $q$ imply that
% we can do more operations).}

% \section{Relinearization}

% Remeber we generated another key along with the private and public.
% called $ek=\left(ek_{0},ek_{1}\right)$. using this key as randomness
% source, we can relinearize the result of multiplication: the new ciphertext
% would be :
% \begin{align*}
% c_{1} & =\left[C_{1}^{*}+ek_{0}\cdot C_{3}^{*}\right]_{q}\\
% c_{2} & =\left[C_{2}^{*}+ek_{1}\cdot C_{3}^{*}\right]_{q}
% \end{align*}
% Remember, decryption is : $c_{1}+c_{2}\cdot sk$. After doing that,
% the decryption would result with: 
% \[
% C_{1}^{*}+C_{2}^{*}\cdot sk+C_{3}^{*}\cdot sk^{2}+C_{3}^{*}\cdot e
% \]
%  which would decrypt just fine, but with a big error $\left(C_{3}^{*}e\right)$!
% We can fix that by using base decomposition.


% \section{Base Decomposition}
% \section{Mod Switching}

% \section{Choosing Parameters}

